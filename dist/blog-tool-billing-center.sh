#!/bin/bash

# MIT License
# 
# Copyright (c) 2025 ç„¦æ£šå­
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

# Author       : jiaopengzi
# Blog         : https://jiaopengzi.com
# Description  : åšå®¢ sh å·¥å…·

set -e

# å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•ç»å¯¹è·¯å¾„
ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" >/dev/null 2>&1 && pwd -P)"
# # å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•ç›¸å¯¹è·¯å¾„
# ROOT_DIR="$(dirname "${BASH_SOURCE[0]}")"

### content from config/user_billing_center.sh
# å½“å‰æ–‡ä»¶ä¸æ£€æµ‹æœªä½¿ç”¨çš„å˜é‡
# shellcheck disable=SC2034

#==============================ç”¨æˆ·ä¿®æ”¹çš„é…ç½®(billing center) å¼€å§‹==============================
# pgsql æ•°æ®åº“é…ç½®(billing center)
POSTGRES_USER_BILLING_CENTER="billing_center"   # æ•°æ®åº“ç”¨æˆ·å
POSTGRES_PASSWORD_BILLING_CENTER="123456"       # æ•°æ®åº“ç”¨æˆ·å¯†ç 
POSTGRES_DB_BILLING_CENTER="billing_center_jpz" # åº”ç”¨ç¨‹åºæ•°æ®åº“åç§°
POSTGRES_PORT_BILLING_CENTER="5433"             # åº”ç”¨ç¨‹åºæ•°æ®åº“ç«¯å£

# redis é…ç½®(billing center)
REDIS_BASE_PORT_BILLING_CENTER="8002"  # redis èµ·å§‹ç«¯å£å·
REDIS_PASSWORD_BILLING_CENTER="123456" # redis å¯†ç 

# æ—¥å¿—çº§åˆ«ï¼šerror(1) < warn(2) < info(3) < debug(4), é»˜è®¤è®°å½•infoåŠä»¥ä¸Š
LOG_LEVEL="info"

# æ—¥å¿—æ–‡ä»¶è·¯å¾„, é»˜è®¤åœ¨ blog-tool æ ¹ç›®å½•ä¸‹
LOG_FILE="$ROOT_DIR/blog_tool.log"
#==============================ç”¨æˆ·ä¿®æ”¹çš„é…ç½®(billing center) ç»“æŸ==============================

### content from utils/log.sh
# ANSIé¢œè‰²å®šä¹‰
RED='\033[0;31m'    # é”™è¯¯(çº¢)
YELLOW='\033[0;33m' # è­¦å‘Š(é»„)
GREEN='\033[0;32m'  # ä¿¡æ¯(ç»¿)
BLUE='\033[0;34m'   # è°ƒè¯•(è“)
NC='\033[0m'        # é‡ç½®é¢œè‰²

# å°†æ—¥å¿—çº§åˆ«å­—ç¬¦ä¸²è½¬ä¸ºæ•°å€¼(ç”¨äºä¼˜å…ˆçº§æ¯”è¾ƒ)
get_level_num() {
    local level="$1"
    case "$level" in
    error) echo 1 ;;
    warn) echo 2 ;;
    info) echo 3 ;;
    debug) echo 4 ;;
    *) echo 5 ;; # æ— æ•ˆçº§åˆ«, é»˜è®¤ä¸è®°å½•
    esac
}

# æ ¸å¿ƒæ—¥å¿—å‡½æ•°(ä¸å†å¤„ç† caller_info, ç”±è°ƒç”¨æ–¹ä¼ å…¥)
# å‚æ•°ï¼š$1=æ—¥å¿—çº§åˆ«, $2=æ—¥å¿—æ¶ˆæ¯, $3=è°ƒç”¨è€…ä¿¡æ¯(æ ¼å¼å¦‚ [file:line])
log() {
    local level="$1"
    local message="$2"
    local caller_info="${3:-}" # ç”±å¿«æ·å‡½æ•°ä¼ å…¥(å¯é€‰)

    # ä¸ºäº†æ—¥å¿—ä¸€è‡´æ€§, ç»™æ¶ˆæ¯åŠ ä¸Šä¸­æ‹¬å·
    message="[$message]"

    # 1. æ ¡éªŒçº§åˆ«æœ‰æ•ˆæ€§
    if ! [[ "error warn info debug" =~ (^| )$level( |$) ]]; then
        echo -e "${RED}[WARN] æ— æ•ˆæ—¥å¿—çº§åˆ«: $level, å·²è½¬ä¸ºinfo${NC}" >&2
        level="info"
        message="æ— æ•ˆçº§åˆ«[$level] â†’ åŸå§‹æ¶ˆæ¯: $message"
    fi

    # 2. è¿‡æ»¤ï¼šå½“å‰çº§åˆ«ä¼˜å…ˆçº§ä½äºå…¨å±€é˜ˆå€¼åˆ™è·³è¿‡
    local current_num global_num
    current_num=$(get_level_num "$level")
    global_num=$(get_level_num "$LOG_LEVEL")
    [ "$current_num" -gt "$global_num" ] && return 0

    # 3. æ ¼å¼åŒ–æ—¥å¿—æ—¶é—´ä¸çº§åˆ«
    local timestamp
    timestamp=$(date +"%Y-%m-%d %H:%M:%S")
    local level_upper="${level^^}"
    local level_pretty
    level_pretty=$(printf "[%-5s]" "$level_upper") # å¦‚ [ERROR]

    # 4. ç»ˆç«¯å¸¦é¢œè‰²è¾“å‡º
    local color
    case "$level" in
    error) color="$RED" ;;
    warn) color="$YELLOW" ;;
    info) color="$GREEN" ;;
    debug) color="$BLUE" ;;
    *) color="" ;;
    esac

    # æ„å»ºå¸¦é¢œè‰²çš„ç»ˆç«¯è¾“å‡º
    # å±å¹•è¾“å‡º: debug çº§åˆ«æ˜¾ç¤ºæ—¶é—´ä¸è°ƒç”¨è€…ä¿¡æ¯, å…¶å®ƒçº§åˆ«åªæ˜¾ç¤ºæ¶ˆæ¯ä¸»ä½“
    local formatted_msg
    if [ "$LOG_LEVEL" = "debug" ]; then
        if [ -n "$caller_info" ]; then
            formatted_msg="[$timestamp] ${level_pretty} ${caller_info} ${message}"
        else
            formatted_msg="[$timestamp] ${level_pretty} [unknown] ${message}"
        fi
    else
        formatted_msg="${message}"
    fi

    # åœ¨æ§åˆ¶å°è¾“å‡ºæ—¥å¿—, >&2 ç¡®ä¿è¾“å‡ºåˆ° stderr, ä¸è¢«å…¶ä»–å‘½ä»¤æ•è·
    echo -e "${color}${formatted_msg}${NC}" >&2

    # 5. åŒæ ·çš„å†…å®¹å†™å…¥æ—¥å¿—æ–‡ä»¶(æ— é¢œè‰²)
    local file_msg
    if [ -n "$caller_info" ]; then
        file_msg="[$timestamp] ${level_pretty} ${caller_info} ${message}"
    else
        file_msg="[$timestamp] ${level_pretty} [unknown] ${message}"
    fi

    # æ£€æŸ¥æ˜¯å¦æ˜¯ root æƒé™è¿è¡Œ
    if [ $UID -ne 0 ]; then
        echo -e "${RED}è¯·ä½¿ç”¨ root æˆ–è€… sudo è¿è¡Œæ­¤è„šæœ¬.${NC}"
        exit 1
    fi

    echo "$file_msg" >>"$LOG_FILE"
}

# **åœ¨å°è£…çš„å¿«æ·å‡½æ•°ä¸­è‡ªåŠ¨æ·»åŠ è°ƒç”¨è€…ä¿¡æ¯, ä¸èƒ½åœ¨è¿›è¡Œå°è£…, å¦åˆ™è¡Œå·ä¸å‡†ç¡®**
# ä½¿ç”¨ BASH_LINENO[0] è·å–ç”¨æˆ·è°ƒç”¨ log_xxx() çš„è¡Œå·

log_error() {
    local message="$1"
    local caller_info="[${BASH_SOURCE[1]##*/}:${BASH_LINENO[0]}]"
    log "error" "$message" "$caller_info"
}

log_warn() {
    local message="$1"
    local caller_info="[${BASH_SOURCE[1]##*/}:${BASH_LINENO[0]}]"
    log "warn" "$message" "$caller_info"
}

log_info() {
    local message="$1"
    local caller_info="[${BASH_SOURCE[1]##*/}:${BASH_LINENO[0]}]"
    log "info" "$message" "$caller_info"
}

log_debug() {
    local message="$1"
    local caller_info="[${BASH_SOURCE[1]##*/}:${BASH_LINENO[0]}]"
    log "debug" "$message" "$caller_info"
}

# å…è´£å£°æ˜ä¿¡æ¯
disclaimer_msg() {
    # æ£€æŸ¥å…è´£å£°æ˜æ¥å—æ ‡è®°æ–‡ä»¶
    if [ -f "$BLOG_TOOL_ENV/disclaimer_accepted" ]; then
        # æ ‡å¿—æ–‡ä»¶ä¸­åªæœ‰ä¸€è¡Œä¿¡æ¯, è®°å½•ç”¨æˆ·æ¥å—æ—¶é—´, è¯»å–å‡ºæ¥å‘ŠçŸ¥ç”¨æˆ·
        local accept_time
        accept_time=$(grep "ç”¨æˆ·æ¥å—æ—¶é—´:" "$BLOG_TOOL_ENV/disclaimer_accepted" | cut -d' ' -f2-)
        log_debug "æ‚¨å·²äº ${accept_time} æ¥å—å…è´£å£°æ˜ï¼Œç»§ç»­ä½¿ç”¨æœ¬å·¥å…·ã€‚"
        return
    fi

    # æ˜¾ç¤ºå…è´£å£°æ˜å†…å®¹
    local msg
    msg=$(
        cat <<EOL

===============================================
                    å…è´£å£°æ˜                                      
===============================================
æœ¬å·¥å…·æŒ‰åŸæ ·æä¾›ï¼Œä½¿ç”¨è€…éœ€è‡ªè¡Œæ‰¿æ‹…é£é™©ã€‚
å¼€å‘è€…ä¸å¯¹å› ä½¿ç”¨æœ¬å·¥å…·è€Œäº§ç”Ÿçš„ä»»ä½•ç›´æ¥æˆ–é—´æ¥æŸå¤±è´Ÿè´£ã€‚
===============================================

EOL
    )

    echo -e "${YELLOW}${msg}${NC}" >&2

    # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
    read -rp "æ˜¯å¦ç»§ç»­ä½¿ç”¨æœ¬å·¥å…·ï¼Ÿ(y/n): " choice
    case "$choice" in
    y | Y)
        # åˆ›å»ºé…ç½®ç›®å½•
        if [ ! -d "$BLOG_TOOL_ENV" ]; then
            mkdir -p "$BLOG_TOOL_ENV"
        fi

        # åˆ›å»ºå…è´£å£°æ˜å·²æ¥å—çš„æ ‡è®°æ–‡ä»¶
        sudo touch "$BLOG_TOOL_ENV/disclaimer_accepted" >/dev/null 2>&1

        # å†™å…¥ç”¨æˆ·æ¥å—æ—¶é—´
        echo "ç”¨æˆ·æ¥å—æ—¶é—´: $(date +"%Y-%m-%d %H:%M:%S")" >"$BLOG_TOOL_ENV/disclaimer_accepted"
        log_info "æ‚¨é€‰æ‹©ç»§ç»­ä½¿ç”¨æœ¬å·¥å…·ã€‚"
        ;;
    n | N)
        echo "å·²é€€å‡ºã€‚"
        exit 0
        ;;
    *)
        echo "æ— æ•ˆè¾“å…¥ï¼Œå·²é€€å‡ºã€‚"
        exit 1
        ;;
    esac
}

show_logo() {
    # ç»ˆç«¯logoæ¬¢è¿ç•Œé¢
    # https://patorjk.com/software/taag/#p=display&f=ANSI+Shadow&t=j+i+a+o+p+e+n+g+z+i&x=none&v=4&h=4&w=80&we=false

    # æ‰“å°è®¿é—®åœ°å€
    local msg
    msg=$(
        cat <<EOL

         â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ•—
         â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•”â•â•â•â•â•    â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â•â•â•â•â•     â•šâ•â•â–ˆâ–ˆâ–ˆâ•”â•    â–ˆâ–ˆâ•‘
         â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—      â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ•”â•     â–ˆâ–ˆâ•‘
    â–ˆâ–ˆ   â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â•â•â•â•     â–ˆâ–ˆâ•”â•â•â•      â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ•”â•      â–ˆâ–ˆâ•‘
    â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•    â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘    â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•    â–ˆâ–ˆâ•‘         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘    â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—    â–ˆâ–ˆâ•‘
     â•šâ•â•â•â•â•     â•šâ•â•    â•šâ•â•  â•šâ•â•     â•šâ•â•â•â•â•â•     â•šâ•â•         â•šâ•â•â•â•â•â•â•    â•šâ•â•  â•šâ•â•â•â•     â•šâ•â•â•â•â•â•     â•šâ•â•â•â•â•â•â•    â•šâ•â•
                                                                                                              
EOL
    )

    msg+="\n    æ¬¢è¿ä½¿ç”¨ blog-tool éƒ¨ç½²è„šæœ¬!\n"

    echo -e "${GREEN}${msg}${NC}" >&2
}

PY_BASE64_MAIN='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'
# shellcheck disable=SC2034

RUN_MODE="pro"

DATA_VOLUME_DIR="$ROOT_DIR/volume"

BLOG_TOOL_ENV="$DATA_VOLUME_DIR/blog_tool_env"

BASE_SOFTWARE_LIST=(
    sudo
    neovim
    git
    curl
    wget
    unzip
    zip
    tar
    gzip
    ca-certificates
    net-tools
    openvswitch-switch
    openssh-server
    bc
    aptitude
    cron
    jq
    python3
)

IS_INSTALL_SOFTWARE=""

DOCKER_CE_SOURCES=(
    "https://mirrors.aliyun.com/docker-ce|é˜¿é‡Œäº‘å…¬ç½‘"
    "http://mirrors.cloud.aliyuncs.com|é˜¿é‡Œäº‘å†…ç½‘"
    "http://mirrors.aliyuncs.com|é˜¿é‡Œäº‘å†…ç½‘ç»å…¸"
    "https://mirrors.163.com/docker-ce|ç½‘æ˜“äº‘"
    "https://mirrors.cernet.edu.cn/docker-ce|ä¸­å›½æ•™è‚²ç½‘"
    "https://mirrors.tuna.tsinghua.edu.cn/docker-ce|æ¸…åå¤§å­¦"
    "https://mirrors.huaweicloud.com/docker-ce|åä¸ºäº‘"
    "https://mirrors.cmecloud.cn/docker-ce|ä¸­å›½ç§»åŠ¨äº‘"
    "https://mirror.azure.cn/docker-ce|Azure ä¸­å›½"
    "https://mirrors.pku.edu.cn/docker-ce|åŒ—äº¬å¤§å­¦"
    "https://mirrors.zju.edu.cn/docker-ce|æµ™æ±Ÿå¤§å­¦"
    "https://mirrors.nju.edu.cn/docker-ce|å—äº¬å¤§å­¦"
    "https://mirror.sjtu.edu.cn/docker-ce|ä¸Šæµ·äº¤é€šå¤§å­¦"
    "https://mirrors.cqupt.edu.cn/docker-ce|é‡åº†é‚®ç”µå¤§å­¦"
    "https://mirrors.ustc.edu.cn/docker-ce|ä¸­å›½ç§‘å­¦æŠ€æœ¯å¤§å­¦"
    "https://mirror.iscas.ac.cn/docker-ce|ä¸­å›½ç§‘å­¦é™¢"
    "https://download.docker.com|å®˜æ–¹æº"
)

DOCKER_HUB_REGISTRY="docker.io" # docker hub ä»“åº“åœ°å€
DOCKER_HUB_OWNER="jiaopengzi"   # docker hub ç”¨æˆ·å

START_TIME=$(date +%s) # è®°å½•å¼€å§‹æ—¶é—´
APP_NAME="jpz"         # åº”ç”¨åç§° ä¸èƒ½åŒ…å«å¤§å†™å­—æ¯å’Œå­—ç¬¦
DISPLAY_COLS=3         # è¾“å‡ºæ˜¾ç¤ºçš„åˆ—æ•°, ç”¨äºè¾“å‡ºå¯¹é½, ä¸€èˆ¬ä¸º 3, å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´

if command -v ifconfig >/dev/null 2>&1; then
    HOST_INTRANET_IP=$(ifconfig | sed -n '/^[eE]/,+3p' | grep 'inet ' | awk '{print $2}')

    HOST_INTRANET_MARK=$(ifconfig | sed -n '/^[eE]/,+3p' | grep 'inet ' | awk '{print $4}')
else
    HOST_INTRANET_IP="127.0.0.1"
    HOST_INTRANET_MARK="255.0.0.0"
fi

CA_CERT_DIR="$DATA_VOLUME_DIR/certs_ca"
CERT_DAYS_VALID=3650

IMG_VERSION_REDIS="8.4.0"    # redis ç‰ˆæœ¬
IMG_VERSION_PGSQL="18.1"     # pgsql ç‰ˆæœ¬
IMG_VERSION_PGSQL_MAJOR="18" # pgsqlä¸»è¦ç‰ˆæœ¬å·

IMG_VERSION_ES="9.2.4"     # 7.17.28 8.18.1
IMG_VERSION_KIBANA="9.2.4" # ä¸ es ä¿æŒç‰ˆæœ¬ä¸€è‡´

JPZ_UID=2025    # æœåŠ¡ç«¯ç”¨æˆ·
JPZ_GID=2025    # æœåŠ¡ç«¯ç”¨æˆ·ç»„
DB_UID=999      # æ•°æ®åº“ç”¨æˆ· id
DB_GID=999      # æ•°æ®åº“ç”¨æˆ·ç»„ id
ES_UID=1000     # es ç”¨æˆ· id
ES_GID=0        # es ç”¨æˆ·ç»„ id
KIBANA_UID=1000 # kibana ç”¨æˆ· id
KIBANA_GID=0    # kibana ç”¨æˆ·ç»„ id
CLIENT_UID=101  # å‰ç«¯ç”¨æˆ· id (nginx)
CLIENT_GID=101  # å‰ç«¯ç”¨æˆ·ç»„ id (nginx)
SERVER_UID=2024 # åç«¯ç”¨æˆ· id (Dockerfileè‡ªè¡Œè®¾ç½®)
SERVER_GID=2024 # åç«¯ç”¨æˆ·ç»„ id (Dockerfileè‡ªè¡Œè®¾ç½®)

BRIDGE_REGISTRY="$APP_NAME-registry$IMG_VERSION_REGISTRY-bridge-net" # ç§æœ‰ä»“åº“ ç½‘æ¡¥
IPV4_BASE_REGISTRY="178.18.10"                                       # ç§æœ‰ä»“åº“ å†…ç½‘èµ·å§‹ IP æ®µ
SUBNET_REGISTRY="$IPV4_BASE_REGISTRY.0/24"                           # ç§æœ‰ä»“åº“ å­ç½‘ç½‘æ®µ
GATEWAY_REGISTRY="$IPV4_BASE_REGISTRY.1"                             # ç§æœ‰ä»“åº“ ç½‘å…³

BRIDGE_PGSQL="$APP_NAME-pgsql-bridge-net" # pgsql ç½‘æ¡¥
IPV4_BASE_PGSQL="178.18.11"               # pgsql å†…ç½‘èµ·å§‹ IP æ®µ
SUBNET_PGSQL="$IPV4_BASE_PGSQL.0/24"      # pgsql å­ç½‘ç½‘æ®µ
GATEWAY_PGSQL="$IPV4_BASE_PGSQL.1"        # pgsql ç½‘å…³

POSTGRES_DOCKER_NAME="pgsql-$IMG_VERSION_PGSQL" # æœåŠ¡åç§°

IPV4_ADDRESS_START=2
POSTGRES_IP="$IPV4_BASE_PGSQL.$((IPV4_ADDRESS_START % 256))" # è‡ªå¢ ä» 2 å¼€å§‹, 1 ä¸ºç½‘å…³

BRIDGE_PGSQL_BILLING_CENTER="$APP_NAME-billing-center-pgsql-bridge-net" # pgsql ç½‘æ¡¥
IPV4_BASE_PGSQL_BILLING_CENTER="178.18.12"                              # pgsql å†…ç½‘èµ·å§‹ IP æ®µ
SUBNET_PGSQL_BILLING_CENTER="$IPV4_BASE_PGSQL_BILLING_CENTER.0/24"      # pgsql å­ç½‘ç½‘æ®µ
GATEWAY_PGSQL_BILLING_CENTER="$IPV4_BASE_PGSQL_BILLING_CENTER.1"        # pgsql ç½‘å…³

POSTGRES_DOCKER_NAME_BILLING_CENTER="pgsql-$IMG_VERSION_PGSQL-billing-center" # æœåŠ¡åç§°

POSTGRES_IP_BILLING_CENTER="$IPV4_BASE_PGSQL_BILLING_CENTER.$((IPV4_ADDRESS_START % 256))" # è‡ªå¢ ä» 2 å¼€å§‹, 1 ä¸ºç½‘å…³

MASTER_COUNT=3                            # ä¸»èŠ‚ç‚¹æ•°é‡
SLAVE_COUNT=3                             # ä»èŠ‚ç‚¹æ•°é‡
BRIDGE_REDIS="$APP_NAME-redis-bridge-net" # redis ç½‘æ¡¥
IPV4_BASE_REDIS="178.18.13"               # redis å†…ç½‘èµ·å§‹ IP æ®µ
SUBNET_REDIS="$IPV4_BASE_REDIS.0/24"      # redis å­ç½‘ç½‘æ®µ
GATEWAY_REDIS="$IPV4_BASE_REDIS.1"        # redis ç½‘å…³

REDIS_START_IP=$IPV4_BASE_REDIS.$((2 % 256)) # ip_node è‡ªå¢ ä» 2 å¼€å§‹, 1 ä¸ºç½‘å…³
REDIS_END_IP=$IPV4_BASE_REDIS.$(((MASTER_COUNT + SLAVE_COUNT + 1) % 256))

BRIDGE_REDIS_BILLING_CENTER="$APP_NAME-redis-billing-center-bridge-net" # redis ç½‘æ¡¥
IPV4_BASE_REDIS_BILLING_CENTER="178.18.14"                              # redis å†…ç½‘èµ·å§‹ IP æ®µ
SUBNET_REDIS_BILLING_CENTER="$IPV4_BASE_REDIS_BILLING_CENTER.0/24"      # redis å­ç½‘ç½‘æ®µ
GATEWAY_REDIS_BILLING_CENTER="$IPV4_BASE_REDIS_BILLING_CENTER.1"        # redis ç½‘å…³

REDIS_START_IP_BILLING_CENTER=$IPV4_BASE_REDIS_BILLING_CENTER.$((2 % 256)) # ip_node è‡ªå¢ ä» 2 å¼€å§‹, 1 ä¸ºç½‘å…³
REDIS_END_IP_BILLING_CENTER=$IPV4_BASE_REDIS_BILLING_CENTER.$(((MASTER_COUNT + SLAVE_COUNT + 1) % 256))

BRIDGE_ES="$APP_NAME-es-bridge-net" # es ç½‘æ¡¥
IPV4_BASE_ES="178.18.15"            # es å†…ç½‘èµ·å§‹ IP æ®µ
SUBNET_ES="$IPV4_BASE_ES.0/24"      # es å­ç½‘ç½‘æ®µ
GATEWAY_ES="$IPV4_BASE_ES.1"        # es ç½‘å…³

ES_START_IP=$IPV4_BASE_ES.$((2 % 256)) # ip_node è‡ªå¢ ä» 2 å¼€å§‹, 1 ä¸ºç½‘å…³
ES_END_IP=$IPV4_BASE_ES.$(((ES_NODE_COUNT + 1) % 256))

ES_CLUSTER_NAME=docker-cluster # é›†ç¾¤åç§°
ES_LICENSE=basic               # è®¾ç½® es çš„è®¸å¯è¯, é»˜è®¤ä¸º basic
ES_PORT=9200                   # es ç«¯å£, å¦‚æœä½¿ç”¨ 127.0.0.1:9200 åˆ™è¡¨ç¤ºåªèƒ½æœ¬åœ°è®¿é—®
KIBANA_PORT=5601               # kibana ç«¯å£

MEM_LIMIT_ES="mem_limit: 1288490188"     # å†…å­˜é™åˆ¶ es (bytes)
MEM_LIMIT_KIBANA="mem_limit: 1073741824" # å†…å­˜é™åˆ¶ kibana

ES_JAVA_OPTS_ENV="- ES_JAVA_OPTS=-Xms512m -Xmx512m"

BRIDGE_SERVER="$APP_NAME-bridge-server" # server ç½‘æ¡¥
IPV4_BASE_SERVER="178.18.16"            # SERVER å†…ç½‘èµ·å§‹ IP æ®µ
SUBNET_SERVER="$IPV4_BASE_SERVER.0/24"  # server å­ç½‘ç½‘æ®µ
GATEWAY_SERVER="$IPV4_BASE_SERVER.1"    # server ç½‘å…³

BRIDGE_BILLING_CENTER="$APP_NAME-bridge-billing-center" # server ç½‘æ¡¥
IPV4_BASE_BILLING_CENTER="178.18.17"                    # SERVER å†…ç½‘èµ·å§‹ IP æ®µ
SUBNET_BILLING_CENTER="$IPV4_BASE_BILLING_CENTER.0/24"  # server å­ç½‘ç½‘æ®µ
GATEWAY_BILLING_CENTER="$IPV4_BASE_BILLING_CENTER.1"    # server ç½‘å…³

BRIDGE_CLIENT="$APP_NAME-bridge-client"    # client ç½‘æ¡¥
IPV4_BASE_CLIENT="178.18.18"               # CLIENT å†…ç½‘èµ·å§‹ IP æ®µ
SUBNET_CLIENT="$IPV4_BASE_CLIENT.0/24"     # client å­ç½‘ç½‘æ®µ
GATEWAY_CLIENT="$IPV4_BASE_CLIENT.1"       # client ç½‘å…³
CERTS_NGINX="$DATA_VOLUME_DIR/certs_nginx" # nginx è¯ä¹¦

DOCKER_COMPOS_DIR="$DATA_VOLUME_DIR/docker_compose_files"
DOCKER_COMPOSE_FILE_PGSQL="$DOCKER_COMPOS_DIR/compose-pgsql.yaml"
DOCKER_COMPOSE_FILE_PGSQL_BILLING_CENTER="$DOCKER_COMPOS_DIR/compose-pgsql-billing-center.yaml"
DOCKER_COMPOSE_FILE_REDIS="$DOCKER_COMPOS_DIR/compose-redis.yaml"
DOCKER_COMPOSE_FILE_REDIS_BILLING_CENTER="$DOCKER_COMPOS_DIR/compose-redis-billing-center.yaml"
DOCKER_COMPOSE_FILE_ES="$DOCKER_COMPOS_DIR/compose-es.yaml"
DOCKER_COMPOSE_FILE_SERVER="$DOCKER_COMPOS_DIR/compose-server.yaml"
DOCKER_COMPOSE_FILE_BILLING_CENTER="$DOCKER_COMPOS_DIR/compose-billing-center.yaml"
DOCKER_COMPOSE_FILE_CLIENT="$DOCKER_COMPOS_DIR/compose-client.yaml"

DOCKER_COMPOSE_PROJECT_NAME_SERVER="$APP_NAME-server"
DOCKER_COMPOSE_PROJECT_NAME_PGSQL="$APP_NAME-pgsql"
DOCKER_COMPOSE_PROJECT_NAME_PGSQL_BILLING_CENTER="$APP_NAME-pgsql-billing-center"
DOCKER_COMPOSE_PROJECT_NAME_REDIS="$APP_NAME-redis"
DOCKER_COMPOSE_PROJECT_NAME_REDIS_BILLING_CENTER="$APP_NAME-redis-billing-center"
DOCKER_COMPOSE_PROJECT_NAME_ES="$APP_NAME-es"
DOCKER_COMPOSE_PROJECT_NAME_BILLING_CENTER="$APP_NAME-billing-center"
DOCKER_COMPOSE_PROJECT_NAME_CLIENT="$APP_NAME-client"

PY_SCRIPT_FILE="/tmp/embedded_python_main.py"

WEB_INSTALL_SERVER_TIPS="å½“å‰éœ€è¦å…¨æ–°å®‰è£… server æœåŠ¡ï¼Œä¼šä½¿ç”¨åˆå§‹åŒ–è¦†ç›–åŸæœ‰é…ç½®ï¼Œæ˜¯å¦è¿›è¡Œå…¨æ–°å®‰è£… \né»˜è®¤é€‰æ‹©n [y|n]? "
WEB_SET_DB_TIPS="\n================================\næ˜¯å¦ä½¿ç”¨å‰ç«¯ç½‘é¡µå¡«å†™æ•°æ®åº“ä¿¡æ¯?\n\nè¯´æ˜\n  å¦‚æœè‡ªè¡Œå•ç‹¬è®¾ç½®æ•°æ®å°±é€‰æ‹© y.\n  å¦‚æœä½¿ç”¨å½“å‰è„šæœ¬å·¥å…·å®‰è£…äº†æ•°æ®å°±é€‰æ‹© n.\né»˜è®¤é€‰æ‹©n [y|n]? "

# shellcheck disable=SC2034

OPTIONS_BILLING_CENTER=(
    "å®‰è£…ä¾èµ–è½¯ä»¶:install_common_software"
    "æ–°å¢å¿…è¦è¿è¡Œç”¨æˆ·:add_group_user"

    "å®‰è£… docker:install_docker"

    "æ‹‰å–ç”Ÿäº§æ•°æ®åº“é•œåƒ:pull_docker_image_pro_db_billing_center"
    "å®‰è£…æ‰€æœ‰æ•°æ®åº“-è®¡è´¹ä¸­å¿ƒ:install_database_billing_center"
    "åˆ é™¤æ‰€æœ‰æ•°æ®åº“-è®¡è´¹ä¸­å¿ƒ:delete_database_billing_center"

    "æ‹‰å– billing center é•œåƒ:docker_pull_billing_center"

    "å®‰è£… billing center æœåŠ¡:docker_billing_center_install"
    "æ‰“å°è®¡è´¹ä¸­å¿ƒ CA è¯ä¹¦:ca_cert_byte_print"

    "å¯åŠ¨ billing center æœåŠ¡:docker_billing_center_start"
    "åœæ­¢ billing center æœåŠ¡:docker_billing_center_stop"
    "é‡å¯ billing center æœåŠ¡:docker_billing_center_restart"

    "å‡çº§æˆ–å›æ»š billing center:start_or_rollback_billing_center_by_version"

    "åˆ é™¤ billing center æœåŠ¡:docker_billing_center_delete"

    "åˆ é™¤ billing center é•œåƒ:docker_rmi_billing_center"

    "ç›‘æ§ billing center æ—¥å¿—:billing_center_logs"

    "æ¸…ç† docker:docker_clear_cache"

    "é€€å‡º:exit_script"
)

OPTIONS_BILLING_CENTER_NOT_SHOW=(
    "æ‰‹åŠ¨å®‰è£… docker:manual_install_docker"
    "æœ€å¿« docker ce æº:find_fastest_docker_mirror"
    "è®¾ç½® daemon:set_daemon_config"
    "å¸è½½ docker:uninstall_docker"

    "åˆ›å»º billing center é…ç½®ç›®å½•:mkdir_billing_center_volume"
    "åˆ é™¤ billing center é…ç½®ç›®å½•:remove_billing_center_volume"

    "å®‰è£… pgsql è®¡è´¹ä¸­å¿ƒ:install_db_pgsql_billing_center"
    "åˆ é™¤ pgsql è®¡è´¹ä¸­å¿ƒ:delete_db_pgsql_billing_center"
    "å®‰è£… redis è®¡è´¹ä¸­å¿ƒ:install_db_redis_billing_center"
    "åˆ é™¤ redis è®¡è´¹ä¸­å¿ƒ:delete_db_redis_billing_center"
)

OPTIONS_BILLING_CENTER_VALID=(
    "${OPTIONS_BILLING_CENTER[@]}"
    "${OPTIONS_BILLING_CENTER_NOT_SHOW[@]}"
)

gen_ca_cert() {
    log_debug "run gen_ca_cert"

    local ca_cert_dir="$1"                   # CA è¯ä¹¦å­˜æ”¾ç›®å½•
    local days_valid="$2"                    # è¯ä¹¦æœ‰æ•ˆæœŸ
    local ca_key_file="$ca_cert_dir/ca.key"  # CA ç§é’¥æ–‡ä»¶
    local ca_cert_file="$ca_cert_dir/ca.crt" # CA è¯ä¹¦æ–‡ä»¶

    log_info "ç”Ÿæˆç§æœ‰ CA è¯ä¹¦..."

    sudo openssl genpkey -algorithm RSA -out "$ca_key_file"

    sudo openssl req -x509 -new -nodes \
        -key "$ca_key_file" \
        -sha256 \
        -days "$days_valid" \
        -out "$ca_cert_file" \
        -subj "/C=CN/ST=Sichuan/L=Chengdu/O=jpz/OU=dev/CN=$HOST_INTRANET_IP"

    sudo rm -f "$ca_cert_dir/ca.srl"

    log_info "CA è¯ä¹¦å’Œç§é’¥å·²ç”Ÿæˆå¹¶ä¿å­˜åœ¨ $ca_cert_dir ç›®å½•ä¸­ã€‚"
}

generate_instance_cert() {
    log_debug "run generate_instance_cert"

    local name=$1               # å®ä¾‹åç§°
    local dns_list=$2           # DNS åˆ—è¡¨
    local ip_list=$3            # IP åˆ—è¡¨
    local cert_dir=$4           # è¯ä¹¦å­˜æ”¾ç›®å½•
    local days_valid=$5         # è¯ä¹¦æœ‰æ•ˆæœŸ
    local ca_cert_file=$6       # CA è¯ä¹¦æ–‡ä»¶
    local ca_key_file=$7        # CA ç§é’¥æ–‡ä»¶
    local cert_cn="${8:-$name}" # è¯ä¹¦çš„ CN å­—æ®µ, é»˜è®¤ä½¿ç”¨å®ä¾‹åç§°, å¯ä»¥ä¼ å…¥å…¶ä»–å€¼

    sudo openssl genpkey -algorithm RSA -out "$cert_dir/$name.key"

    sudo openssl req -new -key "$cert_dir/$name.key" -out "$cert_dir/$name.csr" -subj "/C=CN/ST=Sichuan/L=Chengdu/O=jpz/OU=it/CN=$cert_cn"

    sudo tee "$cert_dir/$name.cnf" >/dev/null <<EOF
[ req ]
distinguished_name = req_distinguished_name
req_extensions = v3_req
prompt = no

[ req_distinguished_name ]
C = CN
ST = Sichuan
L = Chengdu
O = jpz
OU = it
CN = $cert_cn

[ v3_req ]
subjectAltName = @alt_names

[ alt_names ]
EOF

    local i
    IFS=',' read -ra dns_arr <<<"$dns_list"
    for i in "${!dns_arr[@]}"; do
        echo "DNS.$((i + 1)) = ${dns_arr[$i]}" | sudo tee -a "$cert_dir/$name.cnf"
    done

    IFS=',' read -ra ip_arr <<<"$ip_list"
    for i in "${!ip_arr[@]}"; do
        echo "IP.$((i + 1)) = ${ip_arr[$i]}" | sudo tee -a "$cert_dir/$name.cnf"
    done

    sudo openssl x509 -req -in "$cert_dir/$name.csr" \
        -CA "$ca_cert_file" \
        -CAkey "$ca_key_file" \
        -CAcreateserial \
        -out "$cert_dir/$name.crt" \
        -days "$days_valid" \
        -sha256 \
        -extfile "$cert_dir/$name.cnf" \
        -extensions v3_req

    sudo rm -f "$cert_dir/$name.cnf"
    sudo rm -f "$cert_dir/$name.csr"

    local ca_cert_dir
    ca_cert_dir=$(dirname "$ca_cert_file")
    sudo rm -f "$ca_cert_dir/ca.srl"

    log_info "$name è¯ä¹¦å’Œç§é’¥å·²ç”Ÿæˆå¹¶ä¿å­˜åœ¨ $cert_dir ç›®å½•ä¸­ã€‚"
}

gen_my_ca_cert() {
    log_debug "run gen_my_ca_cert"

    # shellcheck disable=SC2153
    setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$CA_CERT_DIR"

    if [ ! -f "$CA_CERT_DIR/ca.crt" ]; then
        gen_ca_cert "$CA_CERT_DIR" "$CERT_DAYS_VALID"
    else
        log_warn "CA è¯ä¹¦å·²å­˜åœ¨, è·³è¿‡ç”Ÿæˆ."
    fi
}

gen_client_nginx_cert() {
    setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$CERTS_NGINX"

    if [ ! -f "$CERTS_NGINX/cert.pem" ]; then
        generate_instance_cert "cert" \
            "localhost,127.0.0.1,$HOST_INTRANET_IP,$PUBLIC_IP_ADDRESS" \
            "127.0.0.1,$HOST_INTRANET_IP,$PUBLIC_IP_ADDRESS" \
            "$CERTS_NGINX" \
            "$CERT_DAYS_VALID" \
            "$CA_CERT_DIR/ca.crt" \
            "$CA_CERT_DIR/ca.key" \
            "$HOST_INTRANET_IP"

        sudo mv "$CERTS_NGINX/cert.crt" "$CERTS_NGINX/cert.pem"
    else
        log_warn "å‰ç«¯ nginx è¯ä¹¦å·²å­˜åœ¨, è·³è¿‡ç”Ÿæˆ."
    fi
}

# shellcheck disable=SC2034

export LC_ALL=C.UTF-8

check_is_root() {
    log_debug "run check_is_root"

    if [ $UID -ne 0 ]; then
        log_error "è¯·ä½¿ç”¨ root æˆ–è€… sudo è¿è¡Œæ­¤è„šæœ¬."
        exit 1
    fi
}

check_character() {
    log_debug "run check_is_character"

    read -r chn_chars eng_chars <<<"$(count_chars "æµ‹è¯•Testä¸­æ–‡å­—ç¬¦English123456")"

    if [[ $chn_chars -ne 6 || $eng_chars -ne 17 ]]; then
        log_warn "å½“å‰ç¯å¢ƒä¸‹å­—ç¬¦è®¡ç®—å¼‚å¸¸, è¯·è®¾ç½®ç³»ç»Ÿè¯­è¨€ä¸º UTF-8 ç¼–ç æ ¼å¼."
    fi
}

check_env_path() {
    log_debug "run check_env_path"

    local paths_to_check=("/usr/bin" "/bin" "/usr/sbin" "/sbin")
    local missing_paths=()
    for path in "${paths_to_check[@]}"; do
        if ! echo "$PATH" | grep -qE "(^|:)$path(:|$)"; then
            missing_paths+=("$path")
        fi
    done

    if [ ${#missing_paths[@]} -ne 0 ]; then
        printf '\nç¯å¢ƒå˜é‡ PATH ä¸­ç¼ºå°‘ä»¥ä¸‹è·¯å¾„: %s\n\n' "${missing_paths[*]}"
        is_add=$(read_user_input "æ˜¯å¦å°†å®ƒä»¬æ·»åŠ åˆ° PATH ä¸­ä»¥ç¡®ä¿è„šæœ¬æ­£å¸¸è¿è¡Œ.(é»˜è®¤n) [y|n]? " "n")
        if [ "$is_add" == "y" ]; then
            export_cmd="export PATH=\$PATH$(printf ':%s' "${missing_paths[@]}")"
            printf '%s\n' "$export_cmd" >>"$HOME/.bashrc"
            printf '%s\n' "$export_cmd" >>"/root/.bashrc"

            log_info "å·²å°†ä»¥ä¸‹è·¯å¾„æ·»åŠ åˆ°ç¯å¢ƒå˜é‡ PATH ä¸­: ${missing_paths[*]}"
            log_warn "è¯·é‡æ–°ç™»å½•ç»ˆç«¯æˆ–è¿è¡Œ 'source ~/.bashrc' ä»¥ä½¿æ›´æ”¹ç”Ÿæ•ˆ."
            exit 0
        else
            log_warn "æœªå°†ç¼ºå°‘çš„è·¯å¾„: ${missing_paths[*]} æ·»åŠ åˆ°ç¯å¢ƒå˜é‡ PATH ä¸­, è„šæœ¬æ— æ³•æ­£å¸¸è¿è¡Œ."
        fi
    fi
}

check_install_base() {
    log_debug "run check_install_base"
    local which_software_list=(
        sudo
        curl
        git
        wget
        unzip
        zip
        tar
        gzip
        bc
        jq
        python3
    )
    local missing_commands=()
    for cmd in "${which_software_list[@]}"; do
        if ! command -v "$cmd" >/dev/null 2>&1; then
            missing_commands+=("$cmd")
        fi
    done

    if [ ${#missing_commands[@]} -ne 0 ]; then
        log_warn "æ£€æµ‹åˆ°æœªå®‰è£…åŸºç¡€è½¯ä»¶"
        is_install=$(read_user_input "æ˜¯å¦å¼€å§‹å®‰è£…åŸºç¡€ä¾èµ–è½¯ä»¶(é»˜è®¤n) [y|n]? " "n")
        if [ "$is_install" == "y" ]; then
            log_info "å¼€å§‹å®‰è£…åŸºç¡€è½¯ä»¶..."
            install_common_software
            log_info "åŸºç¡€è½¯ä»¶å®‰è£…å®Œæˆ, è¯·é‡æ–°è¿è¡Œè„šæœ¬."
            exit 0
        else
            log_error "æœªå®‰è£…åŸºç¡€è½¯ä»¶: ${missing_commands[*]}, è„šæœ¬æ— æ³•æ­£å¸¸è¿è¡Œ."
            exit 0
        fi
    fi
}

load_interactive_config() {
    local var_name=$1
    local config_file=$2
    local prompt_msg=$3
    local default_value=$4

    if [ -z "${!var_name}" ]; then
        if [ -f "$config_file" ]; then
            local file_value
            file_value=$(cat "$config_file")
            if [ -z "$file_value" ]; then
                log_error "$config_file æ–‡ä»¶ä¸ºç©º, è¯·å†™å…¥æœ‰æ•ˆå€¼"
            else
                printf -v "$var_name" '%s' "$file_value"
            fi
        else
            printf "\n%s (é»˜è®¤: %s), å›è½¦ä½¿ç”¨é»˜è®¤å€¼: " "$prompt_msg" "$default_value"
            read -r user_input
            if [ -z "$user_input" ]; then
                printf -v "$var_name" '%s' "$default_value"
            else
                printf -v "$var_name" '%s' "$user_input"
            fi
        fi
    fi

    echo "${!var_name}" | sudo tee "$config_file" >/dev/null
}

load_config_from_file_and_validate() {
    local var_name=$1
    local config_file=$2
    local error_prefix=${3:-""}
    local must_exist=${4:-"true"}

    if [ -e "$config_file" ]; then
        if [ ! -r "$config_file" ]; then
            log_error "${error_prefix}${config_file} å­˜åœ¨ä½†ä¸å¯è¯», è¯·æ£€æŸ¥æƒé™"
        fi

        local file_value
        IFS= read -r file_value <"$config_file"
        file_value="${file_value#"${file_value%%[![:space:]]*}"}"
        file_value="${file_value%"${file_value##*[![:space:]]}"}"

        if [ -z "$file_value" ]; then
            log_error "${error_prefix}${config_file} æ–‡ä»¶ä¸ºç©º, è¯·å†™å…¥æœ‰æ•ˆå€¼"
        fi

        printf -v "$var_name" '%s' "$file_value"
        return
    fi

    if [ "$must_exist" = true ]; then
        log_error "${error_prefix}${config_file} æ–‡ä»¶ä¸å­˜åœ¨, è¯·åˆ›å»ºå¹¶å†™å…¥æœ‰æ•ˆå€¼"
    fi
}

load_env_or_file_config() {
    local env_var_name=$1
    local var_name=$2
    local config_file=$3
    local error_prefix=${4:-""}

    if [ -n "${!env_var_name:-}" ]; then
        printf -v "$var_name" '%s' "${!env_var_name}"
    else
        load_config_from_file_and_validate "$var_name" "$config_file" "$error_prefix"
    fi
}

check_domain_ip() {
    log_debug "run check_domain_ip"

    if [ ! -d "$BLOG_TOOL_ENV" ]; then
        mkdir -p "$BLOG_TOOL_ENV"
    fi

    load_interactive_config \
        DOMAIN_NAME \
        "$BLOG_TOOL_ENV/domain_name" \
        "è¯·è¾“å…¥æ‚¨çš„åŸŸåå¦‚ï¼šexample.com" \
        "$HOST_INTRANET_IP"

    load_interactive_config \
        PUBLIC_IP_ADDRESS \
        "$BLOG_TOOL_ENV/public_ip_address" \
        "è¯·è¾“å…¥æ‚¨çš„å…¬ç½‘ipå¦‚ï¼š1.2.3.4" \
        "$HOST_INTRANET_IP"
}

check_dev_var() {
    log_debug "run check_dev_var"

    load_config_from_file_and_validate \
        RUN_MODE \
        "$BLOG_TOOL_ENV/run_mode" \
        "è¿è¡Œæ¨¡å¼" \
        "false"

    if run_mode_is_pro; then
        return 0
    fi

    if [ ! -d "$BLOG_TOOL_ENV" ]; then
        mkdir -p "$BLOG_TOOL_ENV"
    fi

    load_config_from_file_and_validate \
        REGISTRY_REMOTE_SERVER \
        "$BLOG_TOOL_ENV/private_registry_remote_server" \
        "ç§æœ‰ä»“åº“åœ°å€"

    load_config_from_file_and_validate \
        REGISTRY_USER_NAME \
        "$BLOG_TOOL_ENV/private_user" \
        "ç§æœ‰ä»“åº“ç”¨æˆ·å"

    load_config_from_file_and_validate \
        REGISTRY_PASSWORD \
        "$BLOG_TOOL_ENV/private_password" \
        "ç§æœ‰ä»“åº“å¯†ç "

    load_interactive_config \
        GIT_PREFIX_LOCAL \
        "$BLOG_TOOL_ENV/git_prefix_local" \
        "è¯·è¾“å…¥å†…ç½‘ Git åœ°å€å‰ç¼€å¦‚ï¼šgit@10.0.0.100" \
        "git@127.0.0.1"

    GIT_LOCAL="$GIT_PREFIX_LOCAL:$GIT_USER"

    load_interactive_config \
        HOST_NAME \
        "$BLOG_TOOL_ENV/host_name" \
        "è¯·è¾“å…¥ä¸»æœºåå¦‚ï¼šmy-host" \
        "$(hostname)"

    load_interactive_config \
        SSH_PORT \
        "$BLOG_TOOL_ENV/ssh_port" \
        "è¯·è¾“å…¥ SSH ç«¯å£" \
        "22"

    load_interactive_config \
        GATEWAY_IPV4 \
        "$BLOG_TOOL_ENV/gateway_ipv4" \
        "è¯·è¾“å…¥é»˜è®¤ç½‘å…³å¦‚ï¼š10.0.0.1" \
        "$(ip route | awk '/default/ {print $3; exit}')"

    load_env_or_file_config \
        DOCKER_HUB_TOKEN \
        DOCKER_HUB_TOKEN \
        "$BLOG_TOOL_ENV/docker_hub_token" \
        "docker hub token"

    load_env_or_file_config \
        GITHUB_TOKEN \
        GITHUB_TOKEN \
        "$BLOG_TOOL_ENV/github_token" \
        "github token"

    load_env_or_file_config \
        GITEE_TOKEN \
        GITEE_TOKEN \
        "$BLOG_TOOL_ENV/gitee_token" \
        "gitee token"
}

update_run_mode() {
    if [ ! -d "$BLOG_TOOL_ENV" ]; then
        mkdir -p "$BLOG_TOOL_ENV"
    fi

    if [ -f "$BLOG_TOOL_ENV/run_mode" ]; then
        RUN_MODE=$(sudo cat "$BLOG_TOOL_ENV/run_mode")
    else
        echo "$RUN_MODE" | tee "$BLOG_TOOL_ENV/run_mode" >/dev/null
    fi

    if [[ "$RUN_MODE" == "pro" ]] && is_mem_greater_than 4; then
        ES_JAVA_OPTS_ENV="# $ES_JAVA_OPTS_ENV"
        MEM_LIMIT_ES="# $MEM_LIMIT_ES"
        MEM_LIMIT_KIBANA="# $MEM_LIMIT_KIBANA"
    fi
}

check_dir() {
    log_debug "run check_dir"

    if [ ! -d "$DATA_VOLUME_DIR" ]; then
        setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$DATA_VOLUME_DIR"
    fi

    if [ ! -d "$BLOG_TOOL_ENV" ]; then
        setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$BLOG_TOOL_ENV"
    fi

    if [ ! -d "$DOCKER_COMPOS_DIR" ]; then
        setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$DOCKER_COMPOS_DIR"
    fi

    if [ ! -d "$CA_CERT_DIR" ]; then
        setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$CA_CERT_DIR"
    fi

    if [ ! -d "$CERTS_NGINX" ]; then
        setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$CERTS_NGINX"
    fi
}

check() {
    log_debug "run check"

    check_is_root
    check_character
    check_env_path
    check_install_base
    check_domain_ip
    check_dev_var
    check_dir
    update_run_mode

    check_password_security

    decode_py_base64_main
}

install_database_billing_center() {
    log_debug "run install_database_billing_center"
    local remove_data_pgsql is_redis_cluster remove_data_redis

    if run_mode_is_dev; then
        remove_data_pgsql=$(read_user_input "[1/3]æ˜¯å¦åˆ é™¤ pgsql_billing_center æ•°æ®åº“ä¿¡æ¯ (é»˜è®¤n) [y|n]? " "n")
        is_redis_cluster=$(read_user_input "[2/3]æ˜¯å¦åˆ›å»º redis_billing_center é›†ç¾¤ (é»˜è®¤n) [y|n]? " "n")
        remove_data_redis=$(read_user_input "[3/3]æ˜¯å¦åˆ é™¤ redis_billing_center æ•°æ®åº“ä¿¡æ¯ (é»˜è®¤n) [y|n]? " "n")
    fi

    if run_mode_is_pro; then
        local pgsql_data_dir="$DATA_VOLUME_DIR/pgsql_billing_center"
        local redis_data_dir="$DATA_VOLUME_DIR/redis_billing_center"

        local has_data=true

        if [ ! -d "$pgsql_data_dir" ] && [ ! -d "$redis_data_dir" ]; then
            has_data=false
        fi

        if [ "$has_data" = true ]; then
            log_warn "æ£€æµ‹åˆ°å·²æœ‰æ•°æ®åº“æ•°æ®, è¯·è°¨æ…æ“ä½œ!"
            remove_data_pgsql=$(read_user_input "[1/2]æ˜¯å¦åˆ é™¤ pgsql_billing_center æ•°æ®åº“ä¿¡æ¯ (é»˜è®¤n) [y|n]? " "n")
            is_redis_cluster="n"
            remove_data_redis=$(read_user_input "[2/2]æ˜¯å¦åˆ é™¤ redis_billing_center æ•°æ®åº“ä¿¡æ¯ (é»˜è®¤n) [y|n]? " "n")
        else
            log_info "æœªæ£€æµ‹åˆ°å·²æœ‰æ•°æ®åº“æ•°æ®, å°†è¿›è¡Œå…¨æ–°å®‰è£…."
            remove_data_pgsql="y"
            is_redis_cluster="n"
            remove_data_redis="y"
        fi
    fi

    echo "$remove_data_pgsql" | install_db_pgsql_billing_center

    {
        echo "$is_redis_cluster"
        echo "$remove_data_redis"
    } | install_db_redis_billing_center
}

delete_database_billing_center() {
    log_debug "run delete_database_billing_center"

    local is_delete # æ˜¯å¦åˆ é™¤å†å²æ•°æ® é»˜è®¤ä¸åˆ é™¤
    is_delete=$(read_user_input "ç¡®è®¤è¦åˆ é™¤è®¡è´¹ä¸­å¿ƒæ•°æ®åº“å—(é»˜è®¤n) [y|n]? " "n")

    if [[ "$is_delete" == "y" ]]; then
        echo "$is_delete" | delete_db_pgsql_billing_center
        echo "$is_delete" | delete_db_redis_billing_center

        log_info "åˆ é™¤è®¡è´¹ä¸­å¿ƒæ•°æ®åº“æˆåŠŸ"
    else
        log_info "æœªåˆ é™¤è®¡è´¹ä¸­å¿ƒæ•°æ®åº“"
    fi
}

setup_directory() {
    log_debug "run setup_directory"

    if [ $# -lt 4 ]; then
        echo "Usage: setup_directory <user> <group> <permissions> <dir1> [<dir2> ...]"
        return 1
    fi

    local user=$1
    local group=$2
    local permissions=$3
    shift 3 # å‚æ•°å·¦ç§»3ä½

    for dir_name in "$@"; do
        if [ ! -d "$dir_name" ]; then
            sudo mkdir -p "$dir_name" # åˆ›å»ºç›®å½•
        fi
        sudo chown -R "$user":"$group" "$dir_name" # é‡æ–°è®¾ç½®ç”¨æˆ·å’Œç»„
        sudo chmod -R "$permissions" "$dir_name"   # è®¾ç½®æƒé™
    done
}

over_write_set_owner() {
    log_debug "run over_write_set_owner"

    if [ $# -ne 5 ]; then # å‚æ•°ä¸ªæ•°å¿…é¡»ä¸º5
        echo "Usage: over_write_set_owner <user> <group> <permissions> <content> <filePath>"
        return 1
    fi

    local user=$1        # ç”¨æˆ·
    local group=$2       # ç»„
    local permissions=$3 # æƒé™
    local content=$4     # å†…å®¹
    local filePath=$5    # æ–‡ä»¶å

    echo "$content" | sudo tee "$filePath" >/dev/null # å†™å…¥æ–‡ä»¶
    sudo chown -R "$user:$group" "$filePath"          # è®¾ç½®æ–‡ä»¶ç”¨æˆ·å’Œç»„
    sudo chmod -R "$permissions" "$filePath"          # è®¾ç½®æ–‡ä»¶æƒé™
}

read_dir_basename_to_str() {
    log_debug "run read_dir_basename_to_str"

    local dir_path=$1
    local file_list=""

    if [ -d "$dir_path" ]; then
        for file in "$dir_path"/*; do
            if [ -f "$file" ]; then
                file_name=$(sudo basename "$file")
                file_list+="$file_name "
            fi
        done
    else
        log_error "ç›®å½• $dir_path ä¸å­˜åœ¨ã€‚"
        return 1
    fi

    echo "$file_list"
}

read_dir_basename_to_list() {
    log_debug "run read_dir_basename_to_list"

    local dir="$1"
    local files=()
    for f in "$dir"/*; do
        files+=("$(sudo basename "$f")")
    done
    printf "%s\n" "${files[@]}"
}

semver_to_docker_tag() {
    log_debug "run semver_to_docker_tag"

    local semver="$1"

    local docker_tag="${semver/\+/-}"

    log_debug "å°†åŸæ¥ SemVer é£æ ¼çš„ç‰ˆæœ¬å·: '$semver' è½¬æ¢ä¸º Docker å…è®¸çš„ Tag: '$docker_tag'"

    echo "$docker_tag"
}

docker_tag_push_docker_hub() {
    log_debug "run docker_tag_push_docker_hub"
    local project=$1
    local version=$2

    log_debug "token é¦–å°¾3ä½: ${DOCKER_HUB_TOKEN:0:3}...${DOCKER_HUB_TOKEN: -3}"

    docker_login_retry "$DOCKER_HUB_REGISTRY" "$DOCKER_HUB_OWNER" "$DOCKER_HUB_TOKEN"

    if sudo docker manifest inspect "$DOCKER_HUB_OWNER/$project:$version" >/dev/null 2>&1; then
        log_warn "Docker Hub é•œåƒ $DOCKER_HUB_OWNER/$project:$version å·²å­˜åœ¨, è·³è¿‡æ¨é€"

        sudo docker logout "$DOCKER_HUB_REGISTRY" || true
        return 0
    fi

    local docker_tag_version
    docker_tag_version=$(semver_to_docker_tag "$version")

    sudo docker tag "$REGISTRY_REMOTE_SERVER/$project:build" "$DOCKER_HUB_OWNER/$project:$docker_tag_version"
    sudo docker tag "$REGISTRY_REMOTE_SERVER/$project:build" "$DOCKER_HUB_OWNER/$project:latest"

    timeout_retry_docker_push "$DOCKER_HUB_OWNER" "$project" "$docker_tag_version"

    waiting 5

    timeout_retry_docker_push "$DOCKER_HUB_OWNER" "$project" "latest"

    sudo docker logout "$DOCKER_HUB_REGISTRY" || true
}

docker_tag_push_private_registry() {
    log_debug "run docker_tag_push_private_registry"
    local project=$1
    local version=$2

    local docker_tag_version
    docker_tag_version=$(semver_to_docker_tag "$version")

    sudo docker tag "$REGISTRY_REMOTE_SERVER/$project:build" "$REGISTRY_REMOTE_SERVER/$project:$docker_tag_version"
    sudo docker tag "$REGISTRY_REMOTE_SERVER/$project:build" "$REGISTRY_REMOTE_SERVER/$project:latest"

    log_debug "å¯†ç  é¦–å°¾3ä½: ${REGISTRY_PASSWORD:0:3}...${REGISTRY_PASSWORD: -3}"

    docker_login_retry "$REGISTRY_REMOTE_SERVER" "$REGISTRY_USER_NAME" "$REGISTRY_PASSWORD"

    timeout_retry_docker_push "$REGISTRY_REMOTE_SERVER" "$project" "$docker_tag_version"

    waiting 5

    timeout_retry_docker_push "$REGISTRY_REMOTE_SERVER" "$project" "latest"

    sudo docker logout "$REGISTRY_REMOTE_SERVER" || true
}

docker_private_registry_login_logout() {
    log_debug "run docker_private_registry_login_logout"

    local run_func="$1"

    log_debug "å¯†ç  é¦–å°¾3ä½: ${REGISTRY_PASSWORD:0:3}...${REGISTRY_PASSWORD: -3}"

    sudo docker login "$REGISTRY_REMOTE_SERVER" -u "$REGISTRY_USER_NAME" --password-stdin <<<"$REGISTRY_PASSWORD"

    $run_func

    sudo docker logout "$REGISTRY_REMOTE_SERVER" || true
}

DOWNLOAD_URL="https://github.com/BtbN/FFmpeg-Builds/releases/download/latest/ffmpeg-n8.0-latest-linux64-gpl-8.0.tar.xz" # BtbN å®˜æ–¹æœ€æ–°é¢„ç¼–è¯‘ç‰ˆä¸‹è½½åœ°å€
TEMP_DIR="/tmp/ffmpeg_install"                                                                                          # ä¸´æ—¶ä¸‹è½½å’Œè§£å‹ç›®å½•
INSTALL_DIR="/usr/local/bin"                                                                                            # å®‰è£…ç›®å½•

install_ffmpeg() {
    log_debug "run install_ffmpeg"
    log_info "å¼€å§‹å®‰è£…é¢„ç¼–è¯‘ç‰ˆ FFmpeg(æ¥è‡ª BtbN å®˜æ–¹æ„å»º)"
    log_info "ä¸‹è½½åœ°å€: $DOWNLOAD_URL"
    log_info "å®‰è£…ç›®å½•: $INSTALL_DIR"

    sudo mkdir -p "$TEMP_DIR"
    cd "$TEMP_DIR" || exit 1

    echo "[1/6] æ­£åœ¨ä¸‹è½½ FFmpeg é¢„ç¼–è¯‘äºŒè¿›åˆ¶åŒ…..."
    sudo wget -O ffmpeg.tar.xz "$DOWNLOAD_URL"

    if [ ! -f "ffmpeg.tar.xz" ]; then
        log_error "ä¸‹è½½å¤±è´¥, è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ä¸‹è½½åœ°å€æ˜¯å¦æœ‰æ•ˆ"
        exit 1
    fi

    echo "[2/6] æ­£åœ¨è§£å‹ ffmpeg.tar.xz..."
    sudo tar -xvf ffmpeg.tar.xz

    FFMPEG_EXTRACTED_DIR=$(sudo find . -type d -name "*linux64-gpl*" | sudo head -n 1)

    if [ -z "$FFMPEG_EXTRACTED_DIR" ]; then
        log_error "æœªæ‰¾åˆ°è§£å‹åçš„ FFmpeg ç›®å½•"
        ls -l
        exit 1
    fi

    echo "[3/6] è§£å‹åˆ°çš„ç›®å½•: $FFMPEG_EXTRACTED_DIR"

    if [ ! -d "$INSTALL_DIR" ]; then
        log_info "åˆ›å»ºå®‰è£…ç›®å½•: $INSTALL_DIR"
        sudo mkdir -p "$INSTALL_DIR"
    fi

    echo "[4/6] æ­£åœ¨å¤åˆ¶ FFmpeg å¯æ‰§è¡Œæ–‡ä»¶åˆ° $INSTALL_DIR ..."
    sudo cp "$FFMPEG_EXTRACTED_DIR/bin/ffmpeg" "$INSTALL_DIR/"
    sudo cp "$FFMPEG_EXTRACTED_DIR/bin/ffprobe" "$INSTALL_DIR/"
    sudo cp "$FFMPEG_EXTRACTED_DIR/bin/ffplay" "$INSTALL_DIR/"

    echo "[5/6] èµ‹æƒå¹¶å®Œæˆå®‰è£…..."
    sudo chmod +x "$INSTALL_DIR/ffmpeg"
    sudo chmod +x "$INSTALL_DIR/ffprobe"
    sudo chmod +x "$INSTALL_DIR/ffplay"

    echo "[6/6] æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
    cd /tmp || exit 1
    sudo rm -rf "$TEMP_DIR"

    log_info "FFmpeg é¢„ç¼–è¯‘ç‰ˆ å®‰è£…å®Œæˆï¼"
    log_info "ğŸ“ FFmpeg å®‰è£…ä½ç½®: $INSTALL_DIR"
    log_info "ğŸ”— å…¨å±€å‘½ä»¤: ffmpeg, ffprobe, ffplay; å¯é€šè¿‡ä»¥ä¸‹å‘½ä»¤éªŒè¯ï¼šffmpeg -version | which ffmpeg"
}

uninstall_ffmpeg() {
    log_debug "run uninstall_ffmpeg"
    log_info "å¼€å§‹å¸è½½ FFmpeg é¢„ç¼–è¯‘ç‰ˆ..."

    sudo rm -f "$INSTALL_DIR/ffmpeg"
    sudo rm -f "$INSTALL_DIR/ffprobe"
    sudo rm -f "$INSTALL_DIR/ffplay"

    log_info "FFmpeg é¢„ç¼–è¯‘ç‰ˆ å·²å¸è½½ï¼"
}

git_clone() {
    log_debug "run git_clone"
    local project_dir="$1"
    local git_prefix="${2:-$GIT_LOCAL}"

    log_debug "HOME $HOME"
    log_debug "whoami $(whoami)"
    log_debug "æ‰§è¡Œå…‹éš†å‘½ä»¤: git clone $git_prefix/$project_dir.git"

    if [ -d "$project_dir" ]; then
        sudo rm -rf "$project_dir"
    fi

    sudo git clone "$git_prefix/$project_dir.git"

    log_debug "æŸ¥çœ‹ git ä»“åº“å†…å®¹\n$(ls -la "$project_dir")\n"
}

git_clone_cd() {
    log_debug "run git_clone_cd"
    local project_dir="$1"
    local git_prefix="${2:-$GIT_LOCAL}"

    git_clone "$project_dir" "$git_prefix"

    cd "$project_dir" || exit
    log_debug "å½“å‰ç›®å½• $(pwd)"
}

git_add_commit_push() {
    log_debug "run git_add_commit_push"

    local commit_msg="$1"
    local force_push="${2:-false}"

    sudo git add .

    sudo git commit -m "$commit_msg"

    if [ "$force_push" = true ]; then
        sudo git push -f origin main
        log_warn "å¼ºåˆ¶æ¨é€ä»£ç åˆ°è¿œç¨‹ä»“åº“"
    else
        sudo git push origin main
        log_info "æ¨é€ä»£ç åˆ°è¿œç¨‹ä»“åº“"
    fi
}

git_status_is_clean() {
    log_debug "run git_status_is_clean"
    if [ -z "$(git status --porcelain)" ]; then
        echo true
    else
        echo false
    fi
}

get_tag_version() {
    log_debug "run get_tag_version"
    local git_tag
    git_tag=sudo git describe --tags --abbrev=0 2>/dev/null | grep -E '^v[0-9]+\.[0-9]+\.[0-9]+$$' || echo "dev"
    echo "$git_tag"
}

create_release_id() {
    log_debug "run create_release_id"

    local api_prefix="$1"               # API æ–‡ä»¶è·¯å¾„
    local token="$2"                    # token
    local repo_owner="$3"               # ä»“åº“æ‰€æœ‰è€…
    local repo_name="$4"                # ä»“åº“åç§°
    local tag="$5"                      # Release çš„ Tag åç§°
    local release_name="$6"             # Release åç§°
    local release_body="$7"             # Release æè¿°
    local platform="${8:-github}"       # å¹³å°: github | gitee
    local target_commitish="${9:-main}" # ç›®æ ‡åˆ†æ”¯, gitee ç‰¹æœ‰å‚æ•°, é»˜è®¤ä¸º main

    log_debug "token é¦–å°¾3ä½: ${token:0:3}...${token: -3}"

    local json_data
    json_data=$(
        jq -n \
            --arg tag_name "$tag" \
            --arg name "$release_name" \
            --arg body "$release_body" \
            --arg target_commitish "$target_commitish" \
            '{
            tag_name: $tag_name,
            name: $name,
            body: $body
        } + (if "'"$platform"'" == "gitee" then {target_commitish: $target_commitish} else {} end)'
    )

    log_debug "åˆ›å»º Release çš„ JSON æ•°æ®: $json_data"

    local release_res
    release_res=$(
        curl -s -X POST \
            -H "Authorization: token $token" \
            -H "Accept: application/vnd.github.v3+json" \
            -H "Content-Type: application/json" \
            "$api_prefix/repos/${repo_owner}/${repo_name}/releases" \
            --data "$json_data"
    )

    local release_id
    release_id=$(echo "$release_res" | jq -r '.id // empty')

    if [ -z "$release_id" ]; then
        log_debug "åˆ›å»º Release å“åº”: $release_res"
        log_error "åˆ›å»º Release å¤±è´¥ï¼Œæœªè·å–åˆ°æœ‰æ•ˆçš„ Release ID"
        exit 1
    fi

    upload_url=$(echo "$release_res" | jq -r '.upload_url' | sed 's/{.*}//')

    echo "$release_id" "$upload_url"
}

artifacts_releases() {
    log_debug "run artifacts_releases"

    local api_prefix="$1"         # API æ–‡ä»¶è·¯å¾„
    local token="$2"              # token
    local repo_owner="$3"         # ä»“åº“æ‰€æœ‰è€…
    local repo_name="$4"          # ä»“åº“åç§°
    local tag="$5"                # Release çš„ Tag åç§°
    local release_name="$6"       # Release åç§°
    local release_body="$7"       # Release æè¿°
    local platform="${8:-github}" # å¹³å°: github | gitee
    shift 8                       # å‰©ä½™å‚æ•°å‡ä¸ºè¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„

    local file_paths=("$@") # æ‰€æœ‰å‰©ä½™å‚æ•°è§†ä¸ºè¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„æ•°ç»„

    if [ ${#file_paths[@]} -eq 0 ]; then
        log_error "æœªæŒ‡å®šè¦ä¸Šä¼ çš„æ–‡ä»¶"
        exit 1
    fi

    log_debug "token é¦–å°¾3ä½: ${token:0:3}...${token: -3}"

    local release_id
    local upload_url

    local release_json
    release_json=$(curl -s -H "Authorization: token $token" "$api_prefix/repos/${repo_owner}/${repo_name}/releases/tags/${tag}")

    local release_id=""
    if echo "$release_json" | grep -q '"id":'; then
        release_id=$(echo "$release_json" | jq -r '.id // empty')
    fi

    if [ -z "$release_id" ]; then
        log_info "åˆ›å»ºæ–°çš„ Releaseï¼š$tag"

        local release_info
        release_info=$(create_release_id "$api_prefix" "$token" "$repo_owner" "$repo_name" "$tag" "$release_name" "$release_body" "$platform" "main")
        read -r __release_id __upload_url <<<"$release_info"
        log_debug "æ–°åˆ›å»ºçš„ Release ID: $release_id"

        release_id="$__release_id"
        upload_url="$__upload_url"
    else
        log_warn "Release å·²å­˜åœ¨ï¼š$tag (idï¼š$release_id)ï¼Œè·³è¿‡åˆ›å»º Release æ­¥éª¤ã€‚"
        return
    fi

    for file_path in "${file_paths[@]}"; do
        if [ -z "$file_path" ]; then
            log_error "æœªæŒ‡å®šæœ‰æ•ˆçš„æ–‡ä»¶è·¯å¾„"
            exit 1
        fi
        if [ ! -f "$file_path" ]; then
            log_error "æ–‡ä»¶æœªæ‰¾åˆ°ï¼š$file_path"
            exit 1
        fi

        if [ "$platform" = "github" ]; then
            upload_to_github_release "$api_prefix" "$token" "$tag" "$file_path" "$upload_url"
        elif [ "$platform" = "gitee" ]; then
            upload_to_gitee_release "$api_prefix" "$token" "$repo_owner" "$repo_name" "$release_id" "$file_path"
        fi
    done

    log_info "ğŸ‰ æ‰€æœ‰æ–‡ä»¶ä¸Šä¼ æµç¨‹å®Œæˆ"
}

common_upload_with_logging() {
    local platform_name="$1"    # å¹³å°åç§°ï¼Œä¾‹å¦‚ "GitHub" æˆ– "Gitee"
    local log_message="$2"      # ç”¨äºå±•ç¤ºçš„æ—¥å¿—ä¿¡æ¯ï¼Œå¦‚ "ğŸ“¦ GitHub Release [v1.0]"
    local upload_func_name="$3" # ä¸Šä¼ é€»è¾‘çš„å‡½æ•°åï¼ˆå­—ç¬¦ä¸²ï¼Œå°†åœ¨ä¸‹é¢é€šè¿‡ $upload_func_name() è°ƒç”¨ï¼‰

    log_debug "run common_upload_with_logging for $platform_name"

    log_info "$log_message: å¼€å§‹ä¸Šä¼ ..."

    start_spinner

    if $upload_func_name; then
        log_info "$platform_name: âœ… ä¸Šä¼ æˆåŠŸ"
        stop_spinner
    else
        stop_spinner
        log_error "$platform_name: âŒ ä¸Šä¼ å¤±è´¥"
        return 1
    fi
}

upload_to_github_release() {
    local api_prefix="$1" # API å‰ç¼€
    local token="$2"      # token
    local tag="$3"        # Release çš„ Tag åç§°
    local file_path="$4"  # è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
    local upload_url="$5" # ä¸Šä¼  URL

    local base_name
    base_name=$(basename "$file_path")

    local encoded_name
    encoded_name=$(jq -nr --arg v "$base_name" '$v|@uri')

    local final_upload_url
    final_upload_url="${upload_url}?name=${encoded_name}"

    log_debug "GitHub ä¸Šä¼  URL: $final_upload_url"

    # shellcheck disable=SC2329
    github_upload() {
        sudo curl -sS -X POST -H "Authorization: token $token" \
            -H "Accept: application/json" \
            -H "Content-Type: application/octet-stream" \
            --data-binary @"$file_path" \
            "$final_upload_url"
    }

    common_upload_with_logging \
        "GitHub" \
        "ğŸ“¦ GitHub Release [$tag]" \
        github_upload
}

upload_to_gitee_release() {
    local api_prefix="$1" # API å‰ç¼€
    local token="$2"      # token
    local repo_owner="$3" # ä»“åº“æ‰€æœ‰è€…
    local repo_name="$4"  # ä»“åº“åç§°
    local release_id="$5" # Release ID
    local file_path="$6"  # è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„

    local base_name
    base_name=$(basename "$file_path")

    # shellcheck disable=SC2329
    gitee_upload() {
        sudo curl -s -X POST \
            -H "Authorization: token $token" \
            -F "file=@\"$file_path\"" \
            -F "name=\"$base_name\"" \
            "${api_prefix}/repos/${repo_owner}/${repo_name}/releases/${release_id}/attach_files"
    }

    common_upload_with_logging \
        "Gitee" \
        "ğŸ“¦ Gitee ReleaseID $release_id" \
        gitee_upload
}

artifacts_releases_with_platform() {
    log_debug "run artifacts_releases_with_platform"

    local repo_owner="$1"         # GitHub ä»“åº“æ‰€æœ‰è€…
    local repo_name="$2"          # GitHub ä»“åº“åç§°
    local tag="$3"                # GitHub Release çš„ Tag åç§°
    local release_name="$4"       # Release åç§°
    local release_body="$5"       # Release æè¿°
    local platform="${6:-github}" # å¹³å°: github | gitee
    shift 6                       # å‰©ä½™å‚æ•°å‡ä¸ºè¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„

    log_debug "artifacts_releases_with_platform å¹³å°: $platform"

    local file_paths=("$@") # æ‰€æœ‰å‰©ä½™å‚æ•°è§†ä¸ºè¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„æ•°ç»„

    if [ ${#file_paths[@]} -eq 0 ]; then
        log_error "æœªæŒ‡å®šè¦ä¸Šä¼ çš„æ–‡ä»¶"
        exit 1
    fi

    local git_api_prefix
    local git_token
    if [ "$platform" = "github" ]; then
        git_api_prefix="$GIT_API_PREFIX_GITHUB"
        git_token="$GITHUB_TOKEN"
        log_debug "artifacts_releases_with_platform ä½¿ç”¨ GitHub API å‰ç¼€: $git_api_prefix"
    elif [ "$platform" = "gitee" ]; then
        git_api_prefix="$GIT_API_PREFIX_GITEE"
        git_token="$GITEE_TOKEN"
        log_debug "artifacts_releases_with_platform ä½¿ç”¨ Gitee API å‰ç¼€: $git_api_prefix"
    fi

    artifacts_releases "$git_api_prefix" "$git_token" "$repo_owner" "$repo_name" "$tag" "$release_name" "$release_body" "$platform" "${file_paths[@]}"
}

download_github_release_assets() {
    log_debug "run download_github_release_assets"
    local repo_owner="$1" # GitHub ä»“åº“æ‰€æœ‰è€…
    local repo_name="$2"  # GitHub ä»“åº“åç§°
    local tag="$3"        # GitHub Release çš„ Tag åç§°
    local file_name="$4"  # æ–‡ä»¶å
    local path="$5"       # å­˜æ”¾è·¯å¾„

    local download_url="https://github.com/$repo_owner/$repo_name/releases/download/$tag/$file_name"

    sudo wget -c "$download_url" -O "$path/$file_name"
}

sync_repo_by_tag() {
    log_debug "run sync_repo_by_tag"
    local project_dir="$1"
    local version="$2"
    local git_repo="${3:-$GIT_GITHUB}"

    git_clone "$project_dir-dev" "$GIT_LOCAL"

    if [ ! -f "$ROOT_DIR/$project_dir-dev/CHANGELOG.md" ]; then
        log_warn "$project_dir-dev ä»“åº“ä¸­ä¸å­˜åœ¨ CHANGELOG.md æ–‡ä»¶, è·³è¿‡æ›´æ–°"
        return
    fi

    git_clone_cd "$project_dir" "$git_repo"

    if sudo git rev-parse --verify "refs/tags/$version" >/dev/null 2>&1; then
        log_warn "Tag '$version' å·²å­˜åœ¨, è·³è¿‡æ›´æ–° CHANGELOG.md"

        cd "$ROOT_DIR" || exit
        return
    else
        log_info "Tag '$version' ä¸å­˜åœ¨, ç»§ç»­æ›´æ–° CHANGELOG.md"
    fi

    sudo cp -f "$ROOT_DIR/$project_dir-dev/CHANGELOG.md" "$ROOT_DIR/$project_dir/CHANGELOG.md"
    sudo cp -f "$ROOT_DIR/$project_dir-dev/LICENSE" "$ROOT_DIR/$project_dir/LICENSE"
    sudo cp -f "$ROOT_DIR/$project_dir-dev/README.md" "$ROOT_DIR/$project_dir/README.md"
    log_info "å¤åˆ¶ CHANGELOG.md åˆ° $project_dir ä»“åº“"

    cd "$ROOT_DIR/$project_dir" || exit
    log_debug "å½“å‰ç›®å½• $(pwd)"

    if [ "$(git_status_is_clean)" = true ]; then
        log_warn "CHANGELOG.md æ— æ”¹åŠ¨, ä¸éœ€è¦æäº¤"
    else
        git_add_commit_push "update to $version"
        log_info "æ›´æ–° $project_dir ä»“åº“çš„ CHANGELOG.md å®Œæˆ"
    fi

    cd "$ROOT_DIR" || exit
}

releases_with_md_platform() {
    log_debug "run releases_with_md_platform"
    local project="$1"
    local version="$2"
    local zip_path="$3"
    local platform="${4:-github}"

    local md
    if [ "$platform" = "github" ]; then
        md=$(
            cat <<EOL
- å¦‚ä½•ä½¿ç”¨ï¼Œè¯·å‚è€ƒ [README.md](https://github.com/jiaopengzi/$project/blob/main/README.md)
- æ›´æ–°å†…å®¹ï¼Œè¯·å‚è€ƒ [CHANGELOG.md](https://github.com/jiaopengzi/$project/blob/main/CHANGELOG.md)
EOL
        )

    elif [ "$platform" = "gitee" ]; then
        md=$(
            cat <<EOL
- å¦‚ä½•ä½¿ç”¨ï¼Œè¯·å‚è€ƒ [README.md](https://gitee.com/jiaopengzi/$project/blob/main/README.md)
- æ›´æ–°å†…å®¹ï¼Œè¯·å‚è€ƒ [CHANGELOG.md](https://gitee.com/jiaopengzi/$project/blob/main/CHANGELOG.md)
EOL
        )

    fi

    artifacts_releases_with_platform "$GIT_USER" "$project" "$version" "$version" "$md" "$platform" "$zip_path"
}

generate_items_exclude() {
    log_debug "run generate_items_exclude"

    local prefix=$1        # å‰ç¼€
    local exclude_index=$2 # æ’é™¤çš„ç´¢å¼•
    local count=$3         # æ€»çš„æ•°é‡
    local result=""

    for ((i = 1; i <= count; i++)); do
        if ((i != exclude_index)); then
            formattedI=$(printf "%02d" $i)
            result+="$prefix-$formattedI,"
        fi
    done

    result=${result%,}

    echo "$result"
}

generate_items_all() {
    log_debug "run generate_items_all"
    
    local prefix=$1 # å‰ç¼€
    local count=$2  # æ€»çš„æ•°é‡
    local result=""

    for ((i = 1; i <= count; i++)); do
        formattedI=$(printf "%02d" $i)
        result+="$prefix-$formattedI,"
    done

    result=${result%,}

    echo "$result"
}

run_mode_is_pro() {
    if [ "$RUN_MODE" == "pro" ]; then
        log_debug "run_mode_is_pro: å½“å‰è¿è¡Œæ¨¡å¼ä¸ºç”Ÿäº§ç¯å¢ƒ"
        return 0
    else
        log_debug "run_mode_is_pro: å½“å‰è¿è¡Œæ¨¡å¼ä¸ºå¼€å‘ç¯å¢ƒ"
        return 1
    fi
}

run_mode_is_dev() {
    if run_mode_is_pro; then
        return 1
    else
        return 0
    fi
}

get_img_prefix() {
    local img_prefix="$DOCKER_HUB_OWNER"

    if run_mode_is_dev; then
        img_prefix="$REGISTRY_REMOTE_SERVER"
    fi

    echo "$img_prefix"
}

version_is_pro() {
    local version="$1"

    if [[ "$version" =~ ^v(0|[1-9][0-9]*)\.(0|[1-9][0-9]*)\.(0|[1-9][0-9]*)$ ]]; then
        log_debug "version_is_pro: $version ç¬¦åˆç”Ÿäº§ç¯å¢ƒç‰ˆæœ¬è§„èŒƒ"
        return 0
    else
        log_debug "version_is_pro: $version ä¸ç¬¦åˆç”Ÿäº§ç¯å¢ƒç‰ˆæœ¬è§„èŒƒ"
        return 1
    fi
}

version_is_dev() {
    local version="$1"
    if version_is_pro "$version"; then
        return 1
    else
        return 0
    fi
}

parsing_version() {
    local version="$1"
    local version_date is_dev

    version_date=$(date +%y%m%d%H%M)

    is_dev=true

    if version_is_pro "$version"; then
        is_dev=false
        echo "$version" "$is_dev"
        return
    fi

    if [[ "$version" == "dev" || -z "$version" ]]; then
        version="dev-$version_date"
    fi

    echo "$version" "$is_dev"
}

get_cidr() {
    local mask=$1

    if ! command -v bc >/dev/null 2>&1; then
        echo "24"
        return
    fi

    IFS='.' read -ra ADDR <<<"$mask"

    binary_mask=""

    for i in "${ADDR[@]}"; do
        binary_part=$(echo "obase=2; $i" | bc)
        binary_mask+=$binary_part
    done

    cidr=$(grep -o "1" <<<"$binary_mask" | wc -l)

    echo "$cidr"
}

check_port_available() {
    local port=$1
    if lsof -i :"$port" >/dev/null; then
        log_error "ç«¯å£ $port è¢«å ç”¨"
        return 1 # ç«¯å£è¢«å ç”¨
    else
        log_info "ç«¯å£ $port å¯ç”¨"
        return 0 # ç«¯å£å¯ç”¨
    fi
}

check_url_accessible() {
    local url=$1
    local timeout=$2

    if [[ -z "$timeout" ]]; then
        timeout=5
    fi

    log_debug "æ­£åœ¨æ£€æŸ¥ URL å¯è®¿é—®æ€§: $url (è¶…æ—¶: ${timeout}s)"
    start_spinner

    if curl -Is --max-time "$timeout" "$url" >/dev/null; then
        log_debug "URL å¯è®¿é—®: $url"
        stop_spinner
        return 0 # URL å¯è®¿é—®
    else
        log_debug "URL ä¸å¯è®¿é—®: $url"
        stop_spinner
        return 1 # URL ä¸å¯è®¿é—®
    fi
}

# shellcheck disable=SC2034

generate_strong_password() {
	log_debug "run generate_strong_password"

	openssl rand -hex 32
}

is_weak_password() {
	log_debug "run is_weak_password"

	local password="$1"
	local password_length=${#password}

	if [[ -z "$password" ]]; then
		return 0
	fi

	if ((password_length < 16)); then
		return 0
	fi

	local -a weak_list=(
		"123456"
		"12345678"
		"1234567890"
		"0123456789"
		"password"
		"qwerty"
		"abc123"
		"admin123"
		"root123"
		"123456789"
		"1234567890123456"
	)

	local weak
	for weak in "${weak_list[@]}"; do
		if [[ "$password" == "$weak" ]]; then
			return 0
		fi
	done

	local first_char="${password:0:1}"
	local same_char_pattern
	same_char_pattern=$(printf '%*s' "$password_length" '' | tr ' ' "$first_char")
	if [[ "$password" == "$same_char_pattern" ]]; then
		return 0
	fi

	return 1
}

_handle_existing_password() {
	local var_name="$1"
	local config_file="$2"
	local description="$3"
	local password user_choice

	IFS= read -r password <"$config_file"

	if is_weak_password "$password"; then
		log_warn "$description å¼ºåº¦ä¸è¶³, å»ºè®®æ›¿æ¢ä¸ºå¼ºå¯†ç "
		user_choice=$(read_user_input "âš ï¸  $description å½“å‰ä¸ºå¼±å¯†ç , æ˜¯å¦è‡ªåŠ¨ç”Ÿæˆå¼ºå¯†ç æ›¿æ¢? (y/n, é»˜è®¤: y): " "y")

		if [[ "$user_choice" == "y" ]]; then
			password=$(generate_strong_password)
			over_write_set_owner "$JPZ_UID" "$JPZ_GID" 600 "$password" "$config_file"
			log_debug "âœ… å·²è‡ªåŠ¨ç”Ÿæˆå¼ºå¯†ç å¹¶å†™å…¥ $config_file"
		else
			log_warn "âš ï¸  ç”¨æˆ·é€‰æ‹©ä¿ç•™å¼±å¯†ç : $description"
		fi
	else
		log_debug "$description å¯†ç å¼ºåº¦æ£€æŸ¥é€šè¿‡"
	fi

	printf -v "$var_name" '%s' "$password"
}

_generate_new_password() {
	local var_name="$1"
	local config_file="$2"
	local description="$3"
	local password

	password=$(generate_strong_password)
	over_write_set_owner "$JPZ_UID" "$JPZ_GID" 600 "$password" "$config_file"
	log_info "âœ… å·²è‡ªåŠ¨ç”Ÿæˆ $description å¹¶å†™å…¥ $config_file"

	printf -v "$var_name" '%s' "$password"
}

check_password_security() {
	log_debug "run check_password_security"

	if [[ ! -d "$BLOG_TOOL_ENV" ]]; then
		mkdir -p "$BLOG_TOOL_ENV"
	fi

	local -a password_map=(
		"POSTGRES_PASSWORD:postgres_password:PostgreSQL æ•°æ®åº“å¯†ç "
		"REDIS_PASSWORD:redis_password:Redis å¯†ç "
		"ELASTIC_PASSWORD:elastic_password:Elasticsearch å¯†ç "
		"KIBANA_PASSWORD:kibana_password:Kibana å¯†ç "
		"POSTGRES_PASSWORD_BILLING_CENTER:postgres_password_billing_center:è®¡è´¹ä¸­å¿ƒ PostgreSQL æ•°æ®åº“å¯†ç "
		"REDIS_PASSWORD_BILLING_CENTER:redis_password_billing_center:è®¡è´¹ä¸­å¿ƒ Redis å¯†ç "
	)

	local entry var_name file_name description
	local config_file

	for entry in "${password_map[@]}"; do
		IFS=':' read -r var_name file_name description <<<"$entry"

		if ! declare -p "$var_name" &>/dev/null; then
			log_debug "$var_name å˜é‡ä¸å­˜åœ¨, è·³è¿‡(å¯èƒ½ä¸åœ¨å½“å‰æ„å»ºç‰ˆæœ¬ä¸­)"
			continue
		fi

		config_file="$BLOG_TOOL_ENV/$file_name"

		if [[ -f "$config_file" ]]; then
			_handle_existing_password "$var_name" "$config_file" "$description"
		else
			_generate_new_password "$var_name" "$config_file" "$description"
		fi
	done
}

export LC_ALL=C.UTF-8

count_chars() {
    local text="$1"

    local chn_chars
    chn_chars=$(echo -n "$text" | grep -oP '\p{Han}' | wc -l)

    local eng_chars
    eng_chars=$(echo -n "$text" | grep -oP '[a-zA-Z0-9]' | wc -l)

    echo "$chn_chars $eng_chars"
}

print_dividers() {
    local start_delimiter=$1 # å¼€å§‹åˆ†éš”ç¬¦
    local col_length=$2      # åˆ—å®½
    local cols=$3            # åˆ—æ•°
    local delimiter=$4       # åˆ†éš”ç¬¦
    local line=''            # åˆå§‹åŒ–åˆ†éš”çº¿

    line+="$start_delimiter"
    for ((c = 0; c < cols; c++)); do
        for ((i = 0; i < col_length; i++)); do
            line+="$delimiter"
        done
        line+="$start_delimiter"
    done

    printf '%s\n' "$line"
}

check_utf8() {
    local locale_output
    locale_output=$(locale | head -n 1)
    local value
    value=$(echo "$locale_output" | cut -d '=' -f 2)
    if echo "$value" | grep -q "UTF-8"; then
        echo true
    else
        echo false
    fi
}

print_options() {
    local display_cols="$1"
    shift

    local options=("$@")                                      # é€‰é¡¹æ•°ç»„
    local count=${#options[@]}                                # é€‰é¡¹æ•°é‡
    local rows=$(((count + display_cols - 1) / display_cols)) # è¡Œæ•°
    local cell_width=50                                       # æ¯ä¸ªå•å…ƒæ ¼çš„å®½åº¦
    local custom_width=6                                      # è‡ªå®šä¹‰å®½åº¦ ä¸»è¦æ˜¯ä¸ºäº†æ˜¾ç¤ºåºå·å’Œç©ºæ ¼
    local col_length=$((cell_width + custom_width - 1))       # åˆ—å®½

    print_dividers "+" $col_length "$display_cols" "-"

    for ((row = 0; row < rows; row++)); do
        printf '|' # æ¯è¡Œå¼€å§‹æ‰“å°å·¦è¾¹æ¡†
        for ((col = 0; col < display_cols; col++)); do
            local idx=$((row + rows * col))
            if ((idx < count)); then
                local option="${options[$idx]}"
                local option_name="${option%%:*}" # æå–é€‰é¡¹åç§°
                local chn_count
                read -r chn_count _ <<<"$(count_chars "$option_name")"

                if [ "$(check_utf8)" == true ]; then
                    words=$((cell_width + chn_count))
                else
                    words=$((cell_width + chn_count / 3)) # ä¸€ä¸ªä¸­æ–‡å­—ç¬¦å  3 ä¸ªè‹±æ–‡å­—ç¬¦çš„ä½ç½® è®¡ç®—è¡¥é½å ä½ç¬¦æ•°é‡
                fi

                printf " %02d " $idx                    # æ‰“å°åºå·
                printf " %-*s|" "$words" "$option_name" # å·¦å¯¹é½å†…å®¹

            else
                printf '%*s|' $col_length ""
            fi
        done
        echo
        if [ "$row" -lt "$((rows - 1))" ]; then
            print_dividers "+" $col_length "$display_cols" "-"
        fi
    done

    print_dividers "+" $col_length "$display_cols" "-"
    echo
}

exit_script() {
    rm -f "${PY_SCRIPT_FILE}"

    log_info "é€€å‡ºè„šæœ¬"

    exit 0
}

is_valid_func() {
    local options=("${!1}")
    local func_name="$2"
    for option in "${options[@]}"; do
        IFS=":" read -r _ function_name <<<"$option"
        if [ "$func_name" == "$function_name" ]; then
            echo "$function_name"
            return 0
        fi
    done
    return 1
}

exec_func() {
    local func="$1"
    if declare -f "$func" >/dev/null; then
        $func
    else
        log_error "æ‰¾ä¸åˆ°å¯¹åº”çš„å‡½æ•°ï¼š$func"
        exit 1
    fi
}

handle_user_input() {
    local options=("$@")
    read -r -p "è¯·è¾“å…¥å·¥å…·æ‰€åœ¨çš„åºå·[0-$((${#options[@]} - 1))] æˆ–è€…ç›´æ¥è¾“å…¥å‡½æ•°åç§°: " raw_choice
    if [[ $raw_choice =~ ^0*[0-9]+$ ]]; then
        choice=$(printf "%d\n" $((10#$raw_choice)) 2>/dev/null)
        if ((choice < 0 || choice >= ${#options[@]})); then
            echo "è¯·è¾“å…¥æ­£ç¡®çš„é€‰é¡¹åºå·"
            exit 1
        fi
        option="${options[$choice]}"
        func_name="${option##*:}" # æå–å‡½æ•°åç§°
    else
        func_name=""

        for option in "${options[@]}"; do
            if [[ "${option##*:}" == "$raw_choice" ]]; then
                func_name="$raw_choice"
                break
            fi
        done
        if [[ -z "$func_name" ]]; then
            echo "æœªæ‰¾åˆ°ä¸è¾“å…¥åŒ¹é…çš„å‡½æ•°åç§°"
            exit 1
        fi

    fi
    exec_func "$func_name"
}

read_user_input() {
    local prompt_text=$1
    local default_value=$2
    local user_input=""

    local formatted_prompt="${prompt_text//\\n/$'\n'}"

    read -r -p "$formatted_prompt" user_input

    if [ -z "$user_input" ]; then
        user_input=$default_value
    fi

    user_input=$(echo "$user_input" | tr '[:upper:]' '[:lower:]')

    echo "$user_input"
}

decode_py_base64_main() {
    log_debug "run decode_py_base64_main"
    echo "${PY_BASE64_MAIN}" | base64 -d | gzip -d >"${PY_SCRIPT_FILE}"
}

extract_changelog_block() {
    log_debug "run extract_changelog_block"

    local changelog_file="$1"
    local changelog_version="$2"

    if [[ ! -s "${PY_SCRIPT_FILE}" ]]; then
        log_error "è§£ç åçš„ Python è„šæœ¬æ–‡ä»¶ä¸ºç©ºæˆ–ä¸å­˜åœ¨"
        exit 1
    fi

    log_debug "è§£ç åçš„ Python è„šæœ¬æ–‡ä»¶å·²åˆ›å»º: ${PY_SCRIPT_FILE}"

    python3 "${PY_SCRIPT_FILE}" extract_changelog_block "$changelog_file" "$changelog_version"
}

extract_changelog_version_date() {
    log_debug "run extract_changelog_version_date"

    local changelog_file="$1"

    if [[ ! -s "${PY_SCRIPT_FILE}" ]]; then
        log_error "è§£ç åçš„ Python è„šæœ¬æ–‡ä»¶ä¸ºç©ºæˆ–ä¸å­˜åœ¨"
        exit 1
    fi

    log_debug "è§£ç åçš„ Python è„šæœ¬æ–‡ä»¶å·²åˆ›å»º: ${PY_SCRIPT_FILE}"

    python3 "${PY_SCRIPT_FILE}" extract_changelog_version_date "$changelog_file"
}

docker_run_registry_new() {
  log_debug "run docker_run_registry_new"

  setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$ROOT_DIR/registry"

  if [ ! -d "$CERTS_NGINX" ]; then
    echo "========================================"
    echo "    è¯·å°†è¯ä¹¦ $CERTS_NGINX æ–‡ä»¶å¤¹æ”¾åˆ°å½“å‰ç›®å½•"
    echo "    è¯ä¹¦æ–‡ä»¶å¤¹ç»“æ„å¦‚ä¸‹:"
    echo "    $CERTS_NGINX"
    echo "    â”œâ”€â”€ cert.key"
    echo "    â””â”€â”€ cert.pem"
    echo "========================================"
    log_error "ç¼ºå°‘ $CERTS_NGINX è¯ä¹¦ç›®å½•, æ— æ³•ç»§ç»­åˆ›å»º registry é•œåƒä»“åº“"
    exit 1
  fi

  cp -r "$CERTS_NGINX" "$ROOT_DIR/registry/certs_nginx"

  cd "$ROOT_DIR/registry" || exit

  log_debug "å½“å‰ç›®å½• $(pwd)"

  setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$ROOT_DIR/registry/auth"
  sudo docker run --entrypoint htpasswd httpd:"$IMG_VERSION_HTTPD" -Bbn "$REGISTRY_USER_NAME" "$REGISTRY_PASSWORD" | sudo tee "$ROOT_DIR/registry/auth/htpasswd" >/dev/null # åˆ›å»ºç”¨æˆ·å¯†ç æ–‡ä»¶

  sudo docker ps -a | grep httpd:"$IMG_VERSION_HTTPD" | awk '{print $1}' | xargs sudo docker rm -f

  setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$ROOT_DIR/registry/data"

  cat >>"$ROOT_DIR/registry/docker-compose.yaml" <<-EOM
# é»˜è®¤æ–‡ä»¶å docker-compose.yml ä½¿ç”¨å‘½ä»¤ sudo docker compose up -d

services:
  registry:
    restart: always
    container_name: 'registry$IMG_VERSION_REGISTRY'
    image: 'registry:$IMG_VERSION_REGISTRY'
    user: '$JPZ_UID:$JPZ_UID'
    ports:
      - 5000:5000
      # - 443:443
    environment:
      # REGISTRY_HTTP_ADDR: 0.0.0.0:443 # 443 å¯ä»¥è‡ªå®šä¹‰æŒ‡å®šå®¹å™¨å†…éƒ¨å¼€æ”¾ç«¯å£
      REGISTRY_HTTP_TLS_CERTIFICATE: /certs/cert.pem # è¯ä¹¦ pem å®¹å™¨å†…éƒ¨è·¯å¾„
      REGISTRY_HTTP_TLS_KEY: /certs/cert.key # è¯ä¹¦ key å®¹å™¨å†…éƒ¨è·¯å¾„
      REGISTRY_AUTH: htpasswd # è®¤è¯æ–¹å¼
      REGISTRY_AUTH_HTPASSWD_PATH: /auth/htpasswd # è®¤è¯æ–‡ä»¶è·¯å¾„
      REGISTRY_AUTH_HTPASSWD_REALM: Registry Realm # è®¤è¯åŸŸ
      REGISTRY_LOG_LEVEL: "warn" # å°†æ—¥å¿—çº§åˆ«è®¾ä¸º warning åŠä»¥ä¸Š
      REGISTRY_TRACING_ENABLED: "false" # æ˜¯å¦å¯ç”¨è¿½è¸ª
      REGISTRY_TRACING_ENDPOINT: "" # è¿½è¸ªç«¯ç‚¹
      OTEL_TRACES_EXPORTER: "none" # ç¦ç”¨ OpenTelemetry traces å¯¼å‡º
      OTEL_EXPORTER_OTLP_ENDPOINT: "" # æ¸…ç©ºé»˜è®¤ OTLP endpoint é¿å…å°è¯•è¿æ¥ localhost:4318
    volumes:
      - $ROOT_DIR/registry/data:/var/lib/registry # æ•°æ®å­˜å‚¨è·¯å¾„
      - $ROOT_DIR/registry/certs_nginx:/certs # è¯ä¹¦å­˜å‚¨è·¯å¾„
      - $ROOT_DIR/registry/auth:/auth # è®¤è¯æ–‡ä»¶å­˜å‚¨è·¯å¾„
    networks: # ç½‘ç»œé…ç½®
      $BRIDGE_REGISTRY: # ç½‘ç»œåç§°

networks: # ç½‘ç»œé…ç½®
  $BRIDGE_REGISTRY: # ç½‘ç»œåç§°
    driver: bridge # ç½‘ç»œé©±åŠ¨
    name: $BRIDGE_REGISTRY # ç½‘ç»œåç§°
    ipam: # IPåœ°å€ç®¡ç†
      config: # IPåœ°å€é…ç½®
        - subnet: "$SUBNET_REGISTRY" # å­ç½‘
          gateway: "$GATEWAY_REGISTRY" # ç½‘å…³
EOM

  sudo docker compose up -d

  sudo docker login "$REGISTRY_REMOTE_SERVER" -u "$REGISTRY_USER_NAME" --password-stdin <<<"$REGISTRY_PASSWORD"
}

retry_with_backoff() {
    local run_func="$1"
    local max_retries=${2:-5}
    local delay=${3:-2}
    local success_msg="$4"
    local error_msg_prefix="$5"
    local retry_on_pattern="$6"

    local attempt=1
    local output
    local status

    start_spinner

    while true; do
        local tmpfile
        tmpfile=$(mktemp) || {
            stop_spinner
            log_error "åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤±è´¥"
            return 1
        }

        if "$run_func" >"$tmpfile" 2>&1; then
            stop_spinner

            cat "$tmpfile"
            rm -f "$tmpfile"

            log_info "$success_msg"
            return 0
        else
            status=$?

            output=$(cat "$tmpfile")

            if [ -z "$retry_on_pattern" ] || echo "$output" | grep -Eiq "$retry_on_pattern"; then
                if [ "$attempt" -ge "$max_retries" ]; then
                    stop_spinner
                    log_error "è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°($max_retries), æ“ä½œä»å¤±è´¥ã€‚è¾“å‡º: $output"
                    return 1
                fi

                log_warn "ç¬¬ ${attempt}/${max_retries} æ¬¡é‡è¯•, ${delay}s åé‡è¯•ã€‚é€€å‡ºç : $status"
                sleep "$delay"
                attempt=$((attempt + 1))
                delay=$((delay * 2))
            else
                stop_spinner
                log_error "${error_msg_prefix}: $output"
                return 1
            fi
        fi
    done
}

docker_login_retry() {

    log_debug "run docker_login_retry"
    local registry_server="$1"
    local username="$2"
    local password="$3"

    log_info "æ­£åœ¨ç™»å½• docker ä»“åº“: $registry_server"

    # shellcheck disable=SC2329
    run() {
        sudo docker login "$registry_server" -u "$username" --password-stdin <<<"$password"
    }

    retry_with_backoff \
        "run" \
        5 \
        2 \
        "ç™»å½•ä»“åº“ $registry_server æˆåŠŸ" \
        "ç™»å½•ä»“åº“å¤±è´¥(éé‡è¯•ç±»é”™è¯¯)" \
        "" # ç™»å½•å¤±è´¥é€šå¸¸é‡è¯•, ä¸è®¾ pattern
}

timeout_retry_docker_push() {
    log_debug "run timeout_retry_docker_push"
    local registry_server_or_user="$1"
    local project=$2
    local version=$3

    local image="$registry_server_or_user/$project:$version"

    log_info "å‡†å¤‡æ¨é€é•œåƒ: $image"

    # shellcheck disable=SC2329
    run() {
        log_debug "æ‰§è¡Œçš„å‘½ä»¤: sudo docker push $image"
        sudo docker push "$image"
    }

    retry_with_backoff \
        "run" \
        5 \
        2 \
        "æ¨é€ $image æˆåŠŸ" \
        "docker push å¤±è´¥(é TLS/è¿æ¥ç±»é”™è¯¯)" \
        "TLS handshake timeout|tls: handshake|tls handshake|x509: certificate|certificate signed by unknown authority|connection reset by peer|connection refused"
}

timeout_retry_docker_pull() {
    log_debug "run timeout_retry_docker_pull"
    local image_name=$1
    local version=$2

    local image="$image_name:$version"

    log_info "å¼€å§‹æ‹‰å–é•œåƒ: $image"

    # shellcheck disable=SC2329
    run() {
        log_debug "æ‰§è¡Œçš„å‘½ä»¤: sudo docker pull $image"
        sudo docker pull "$image"
    }

    retry_with_backoff \
        "run" \
        5 \
        2 \
        "æ‹‰å– $image æˆåŠŸ" \
        "docker pull å¤±è´¥(é TLS/è¿æ¥ç±»é”™è¯¯)" \
        "TLS handshake timeout|tls: handshake|tls handshake|x509: certificate|certificate signed by unknown authority|connection reset by peer|connection refused"
}

docker_build_push_start_server_client() {
    log_debug "run docker_build_push_start_server_client"
    docker_build_push_server_client
    docker_server_client_install
}

get_raw() {
    log_debug "run get_raw"
    local project="$1"
    local file="$2"
    local platform="${3:-github}"

    local raw_url
    if [ "$platform" = "github" ]; then
        raw_url="https://raw.githubusercontent.com/jiaopengzi/$project/refs/heads/main/$file"
    elif [ "$platform" = "gitee" ]; then
        raw_url="https://gitee.com/jiaopengzi/$project/raw/main/$file"
    fi

    echo "$raw_url"
}

get_service_versions() {
    log_debug "run get_service_versions"
    local service_name="${1-blog-client}"

    local raw_url

    start_spinner

    if [[ $(curl -s ipinfo.io/country) == "CN" ]]; then
        log_debug "æ£€æµ‹åˆ°å›½å†…ç½‘ç»œç¯å¢ƒ, ä½¿ç”¨ gitee è·å– $service_name ç‰ˆæœ¬"
        raw_url=$(get_raw "$service_name" "CHANGELOG.md" "gitee")
    else
        log_debug "æ£€æµ‹åˆ°éå›½å†…ç½‘ç»œç¯å¢ƒ, ä½¿ç”¨ github è·å– $service_name ç‰ˆæœ¬"
        raw_url=$(get_raw "$service_name" "CHANGELOG.md" "github")
    fi

    local changelog_temp_file
    changelog_temp_file=$(mktemp)
    curl -sSL "$raw_url" -o "$changelog_temp_file"

    stop_spinner

    extract_changelog_version_date "$changelog_temp_file"
}

show_service_versions() {
    log_debug "run show_service_versions"
    local service_name="${1-blog-client}"

    local versions
    versions=$(get_service_versions "$service_name")

    local formatted_versions=""
    local has_versions=false
    while IFS= read -r line; do
        local date_part version_part formatted_version
        version_part=$(echo "$line" | awk '{print $1}')
        date_part=$(echo "$line" | awk '{print $2}')

        formatted_version="$date_part\t$(semver_to_docker_tag "$version_part")"

        if run_mode_is_pro; then
            if (version_is_pro "$version_part"); then
                formatted_versions+="$formatted_version\n"
                has_versions=true
            fi
        else
            formatted_versions+="$formatted_version\n"
            has_versions=true
        fi

    done <<<"$versions"

    if [ "$has_versions" = false ]; then
        log_warn "æœåŠ¡ $service_name æš‚æ— å¯ç”¨ç‰ˆæœ¬åˆ—è¡¨"
        exit 0
    fi

    formatted_versions=$(echo -e "å‘å¸ƒæ—¥æœŸ\tç‰ˆæœ¬å·\n$formatted_versions" | column -t)

    log_info "\n\næœåŠ¡ $service_name å¯ç”¨ç‰ˆæœ¬åˆ—è¡¨å¦‚ä¸‹:\n\n$formatted_versions\n"
}

check_service_version() {
    log_debug "run check_service_version"
    local service_name="${1-blog-server}"
    local version="$2"

    local versions
    versions=$(get_service_versions "$service_name")

    local version_exists=false

    while IFS= read -r line; do
        local v
        v=$(echo "$line" | awk '{print $1}')

        local formatted_v
        formatted_v=$(semver_to_docker_tag "$v")

        if [[ "$formatted_v" == "$version" ]]; then
            version_exists=true
            break
        fi
    done <<<"$versions"

    if [ "$version_exists" = false ]; then
        log_error "æœåŠ¡ $service_name æœªæ‰¾åˆ°ç‰ˆæœ¬ $version, è¯·æ£€æŸ¥åé‡è¯•"
        exit 1
    fi

    if run_mode_is_pro && (version_is_dev "$version"); then
        log_error "å½“å‰è¿è¡Œæ¨¡å¼ä¸ºç”Ÿäº§ç¯å¢ƒ, ç‰ˆæœ¬ $version ä¸ç¬¦åˆç”Ÿäº§ç¯å¢ƒç‰ˆæœ¬è§„èŒƒ, è¯·æ£€æŸ¥åé‡è¯•"
        exit 1
    fi

    log_info "æœåŠ¡ $service_name æ‰¾åˆ°ç‰ˆæœ¬ $version"
}

get_cpu_logical() {
    grep -c '^processor[[:space:]]*:' /proc/cpuinfo
}

get_mem_gb() {
    awk '/^MemTotal:/ {printf "%.2f\n", $2/1024/1024}' /proc/meminfo
}

is_mem_greater_than() {
    local mem_gb
    mem_gb=$(get_mem_gb)

    log_debug "å½“å‰å†…å­˜: ${mem_gb}GB, é˜ˆå€¼: ${1}GB"

    local threshold=$1
    awk -v mem="$mem_gb" -v thresh="$threshold" 'BEGIN {exit (mem > thresh) ? 0 : 1}'
}

log_timer() {
    local event run_func start_time end_time time_elapsed hours minutes seconds
    event=$1
    run_func=$2
    start_time=${3:-$(date +%s)}

    log_debug "å¼€å§‹æ‰§è¡Œ: ${event}, å¼€å§‹æ—¶é—´: $(date -d "@$start_time" +"%Y-%m-%d %H:%M:%S")"

    $run_func

    end_time=$(date +%s)
    time_elapsed=$((end_time - start_time))
    hours=$((time_elapsed / 3600))
    minutes=$(((time_elapsed / 60) % 60))
    seconds=$((time_elapsed % 60))
    log_info "${event}å…±è®¡ç”¨æ—¶: ${hours}æ—¶${minutes}åˆ†${seconds}ç§’"
}

__spinner_pid=""

start_spinner() {
    if [ -n "$__spinner_pid" ]; then
        return
    fi

    local spinner_frames=("â£¾" "â£½" "â£»" "â¢¿" "â¡¿" "â£Ÿ" "â£¯" "â£·")

    local spin_index=0

    show_spinner() {
        while true; do
            printf "\r%s  " "${spinner_frames[$spin_index]}" >&2
            spin_index=$(((spin_index + 1) % ${#spinner_frames[@]}))
            sleep 0.2
        done
    }

    show_spinner &
    __spinner_pid=$!
}

stop_spinner() {
    if [ -n "$__spinner_pid" ]; then
        if kill -0 "$__spinner_pid" 2>/dev/null; then
            kill "$__spinner_pid" 2>/dev/null || true # kill è¿›ç¨‹, å¿½ç•¥é”™è¯¯é˜²æ­¢è„šæœ¬é€€å‡º
            wait "$__spinner_pid" 2>/dev/null || true # ç­‰å¾…è¿›ç¨‹é€€å‡º, å¿½ç•¥é”™è¯¯é˜²æ­¢è„šæœ¬é€€å‡º
        fi

        printf "\r  \r" >&2 # æ¸…é™¤æ®‹ç•™å¸§
        __spinner_pid=""    # æ¸…ç©ºPIDä»¥é¿å…å†æ¬¡åœæ­¢
    fi
}

waiting() {
    local duration=$1

    if [[ -z "$duration" || "$duration" -le 0 ]]; then
        return
    fi

    start_spinner

    sleep "$duration"

    stop_spinner
}

wait_file_write_complete() {
    log_debug "run wait_file_write_complete"

    log_warn "ç­‰å¾…æ–‡ä»¶å†™å…¥å®Œæˆ, è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´... è¯·å‹¿ä¸­æ–­ï¼"

    local run_func="$1"
    local file_path="$2"
    local timeout=${3:-300}

    local start_time
    start_time=$(date +%s)

    start_spinner

    $run_func

    until sudo [ -f "$file_path" ]; do
        sleep 1

        local current_time
        current_time=$(date +%s)

        local elapsed_time=$((current_time - start_time))

        if [ "$elapsed_time" -ge "$timeout" ]; then
            stop_spinner

            log_error "ç­‰å¾…æ–‡ä»¶å†™å…¥å®Œæˆè¶…æ—¶, å·²è¶…è¿‡ $timeout ç§’, è¯·æ£€æŸ¥ç›¸å…³æ—¥å¿—"
            exit 1
        fi
    done

    stop_spinner

    log_debug "æ–‡ä»¶ $file_path å†™å…¥å®Œæˆ."
}

update_yaml_block() {
    local YAML_FILE="$1"
    local YAML_KEY_LINE="$2"
    local NEW_CONTENT_FILE="$3"

    if [[ -z "$YAML_FILE" || -z "$YAML_KEY_LINE" || -z "$NEW_CONTENT_FILE" ]]; then
        echo "âŒ é”™è¯¯ï¼šè¯·æä¾› YAML æ–‡ä»¶è·¯å¾„ã€YAML key è¡Œ(å¦‚ 'key: |')ã€ä»¥åŠæ–°å†…å®¹æ–‡ä»¶è·¯å¾„"
        echo "   ç”¨æ³•: update_yaml_block \"yamlæ–‡ä»¶è·¯å¾„\" \"yaml_key_line\" \"æ–°å†…å®¹æ–‡ä»¶è·¯å¾„\""
        return 1
    fi

    if ! sudo test -f "$YAML_FILE"; then
        echo "âŒ é”™è¯¯ï¼šYAML æ–‡ä»¶ä¸å­˜åœ¨: $YAML_FILE"
        return 1
    fi

    if ! sudo test -f "$NEW_CONTENT_FILE"; then
        echo "âŒ é”™è¯¯ï¼šæ–°å†…å®¹æ–‡ä»¶ä¸å­˜åœ¨: $NEW_CONTENT_FILE"
        return 1
    fi

    local KEY_LINE_NUM
    KEY_LINE_NUM=$(sudo grep -n "^${YAML_KEY_LINE}$" "$YAML_FILE" | sudo cut -d: -f1)

    if [[ -z "$KEY_LINE_NUM" ]]; then
        echo "âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° YAML key è¡Œ: '$YAML_KEY_LINE', è¯·ç¡®è®¤æ ¼å¼ä¸æ–‡ä»¶ä¸­å®Œå…¨ä¸€è‡´(åŒ…æ‹¬ç¼©è¿›ï¼)"
        return 1
    fi

    local BLOCK_START_LINE=$((KEY_LINE_NUM + 1))
    local TOTAL_LINES
    TOTAL_LINES=$(sudo cat "$YAML_FILE" | wc -l | awk '{print $1}')

    if [[ $BLOCK_START_LINE -gt $TOTAL_LINES ]]; then
        echo "âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° YAML key è¡Œ: '$YAML_KEY_LINE'çš„ä¸‹ä¸€è¡Œä¸å­˜åœ¨, å¯èƒ½æ ¼å¼é”™)"
        return 1
    fi

    local BLOCK_START_LINE_CONTENT
    BLOCK_START_LINE_CONTENT=$(sudo sed -n "${BLOCK_START_LINE}p" "$YAML_FILE")

    local INDENT=""
    local i char
    for ((i = 0; i < ${#BLOCK_START_LINE_CONTENT}; i++)); do
        char="${BLOCK_START_LINE_CONTENT:$i:1}"
        if [[ "$char" == " " ]]; then
            INDENT="${INDENT}${char}"
        else
            break
        fi
    done

    local NEW_CONTENT_RAW
    NEW_CONTENT_RAW=$(sudo cat "$NEW_CONTENT_FILE" 2>/dev/null)

    if [[ -z "$NEW_CONTENT_RAW" ]]; then
        echo "âŒ é”™è¯¯ï¼šæ— æ³•è¯»å–æ–°å†…å®¹æ–‡ä»¶ '$NEW_CONTENT_FILE'ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æƒé™"
        return 1
    fi

    local FORMATTED_BLOCK=""
    while IFS= read -r line; do
        FORMATTED_BLOCK+="${INDENT}${line}"$'\n'
    done <<<"$NEW_CONTENT_RAW"

    local TMP_FILE
    TMP_FILE=$(sudo mktemp)

    if sudo awk -v start_line="$BLOCK_START_LINE" \
        -v indent="$INDENT" \
        -v new_cert="$FORMATTED_BLOCK" \
        '
    BEGIN {
        in_cert_block = 0
        replaced = 0
    }

    NR < start_line {
        print
    }

    NR == start_line {
        current_indent = ""
        for (i = 1; i <= length($0); i++) {
            c = substr($0, i, 1)
            if (c == " ") {
                current_indent = current_indent c
            } else {
                break
            }
        }
        if (current_indent == indent) {
            print new_cert
            in_cert_block = 1
            replaced = 1
        } else {
            print
        }
    }

    NR > start_line {
        if (in_cert_block == 1) {
            current_indent = ""
            for (i = 1; i <= length($0); i++) {
                c = substr($0, i, 1)
                if (c == " ") {
                    current_indent = current_indent c
                } else {
                    break
                }
            }
            if (current_indent == indent) {
            } else {
                in_cert_block = 0
                print $0
            }
        } else {
            print $0
        }
    }
    ' "$YAML_FILE" | sudo tee "$TMP_FILE" >/dev/null; then
        sudo cp "$YAML_FILE" "${YAML_FILE}.bak"
        sudo mv "$TMP_FILE" "$YAML_FILE"
        echo "âœ… æˆåŠŸæ›´æ–° YAML æ–‡ä»¶ä¸­åˆ° YAML key è¡Œ: '$YAML_KEY_LINE' çš„å¤šè¡Œå­—ç¬¦ä¸²å—å†…å®¹"
        echo "ğŸ“‚ åŸæ–‡ä»¶å·²å¤‡ä»½ä¸º: ${YAML_FILE}.bak"
    else
        echo "âŒ æ›¿æ¢å¤±è´¥"
        sudo rm -f "$TMP_FILE"
        return 1
    fi
}

apt_update() {
    log_debug "run apt_update"

    if command -v sudo >/dev/null 2>&1; then
        sudo apt update
    else
        apt update
    fi
}

apt_install_y() {
    log_debug "run apt_install_y"

    sudo apt install -y "$@"
}

detect_system() {
	if [ -f /etc/os-release ]; then
		local id=""
		id=$(grep "^ID=" /etc/os-release 2>/dev/null | cut -d= -f2 | tr -d '"')

		local version_codename=""
		version_codename=$(grep "^VERSION_CODENAME=" /etc/os-release 2>/dev/null | cut -d= -f2 | tr -d '"')

		case "$id" in
		debian)
			SYSTEM_FAMILY="debian"
			SYSTEM_CODENAME="$version_codename"
			case "$version_codename" in
			trixie) SYSTEM_VERSION_NUM="13" ;;
			bookworm) SYSTEM_VERSION_NUM="12" ;;
			bullseye) SYSTEM_VERSION_NUM="11" ;;
			*) SYSTEM_VERSION_NUM="" ;;
			esac
			return 0
			;;
		ubuntu)
			SYSTEM_FAMILY="ubuntu"
			SYSTEM_CODENAME="$version_codename"
			case "$version_codename" in
			noble) SYSTEM_VERSION_NUM="24" ;;
			jammy) SYSTEM_VERSION_NUM="22" ;;
			focal) SYSTEM_VERSION_NUM="20" ;;
			bionic) SYSTEM_VERSION_NUM="18" ;;
			*) SYSTEM_VERSION_NUM="" ;;
			esac
			return 0
			;;
		*)
			return 1
			;;
		esac
	fi

	if [ -f /etc/debian_version ]; then
		SYSTEM_FAMILY="debian"
		SYSTEM_CODENAME="unknown"
		SYSTEM_VERSION_NUM=""
		return 0
	fi

	return 1
}

get_system_family() {
	detect_system
	echo "$SYSTEM_FAMILY"
}

get_system_codename() {
	detect_system
	echo "$SYSTEM_CODENAME"
}

get_system_version_num() {
	detect_system
	echo "$SYSTEM_VERSION_NUM"
}

get_apt_source_base() {
	detect_system
	case "$SYSTEM_FAMILY" in
	debian) echo "http://deb.debian.org/debian" ;;
	ubuntu) echo "http://archive.ubuntu.com/ubuntu" ;;
	*) echo "http://deb.debian.org/debian" ;;
	esac
}

get_docker_repo_path() {
	detect_system
	case "$SYSTEM_FAMILY" in
	debian) echo "debian" ;;
	ubuntu) echo "ubuntu" ;;
	*) echo "debian" ;;
	esac
}

get_backports_source() {
	detect_system
	local base_url
	base_url=$(get_apt_source_base)
	case "$SYSTEM_FAMILY" in
	debian)
		echo "deb $base_url $SYSTEM_CODENAME-backports main contrib non-free-firmware"
		;;
	ubuntu)
		echo "deb $base_url $SYSTEM_CODENAME-backports main restricted universe multiverse"
		;;
	*)
		echo ""
		;;
	esac
}

check_min_version() {
	local min_version="$1"
	detect_system
	[ -z "$SYSTEM_VERSION_NUM" ] && return 1
	[ "$SYSTEM_VERSION_NUM" -ge "$min_version" ] 2>/dev/null
	return $?
}

print_system_info() {
	detect_system
	echo "SYSTEM_FAMILY: $SYSTEM_FAMILY"
	echo "SYSTEM_CODENAME: $SYSTEM_CODENAME"
	echo "SYSTEM_VERSION_NUM: $SYSTEM_VERSION_NUM"
	echo "APT_SOURCE_BASE: $(get_apt_source_base)"
	echo "DOCKER_REPO_PATH: $(get_docker_repo_path)"
	echo "BACKPORTS_SOURCE: $(get_backports_source)"
}

init_system_detection() {
	detect_system
	export SYSTEM_FAMILY
	export SYSTEM_CODENAME
	export SYSTEM_VERSION_NUM

	if [ "$SYSTEM_FAMILY" = "debian" ] || [ "$SYSTEM_FAMILY" = "ubuntu" ]; then
		OLD_SYS_VERSION="$SYSTEM_CODENAME"
		NEW_SYS_VERSION="$SYSTEM_CODENAME"
		NEW_SYS_VERSION_NUM="$SYSTEM_VERSION_NUM"
		export OLD_SYS_VERSION NEW_SYS_VERSION NEW_SYS_VERSION_NUM
	fi
}

install_common_software() {
    log_debug "run install_common_software"

    apt_update

    if command -v sudo >/dev/null 2>&1; then
        sudo apt install -y "${BASE_SOFTWARE_LIST[@]}"
    else
        apt install -y "${BASE_SOFTWARE_LIST[@]}"
    fi

    if ! grep -q "export HISTSIZE=*" "$HOME/.bashrc"; then
        echo 'export HISTSIZE=5000' | tee -a "$HOME/.bashrc"
    fi

    if ! grep -q "export HISTFILESIZE=*" "$HOME/.bashrc"; then
        echo 'export HISTFILESIZE=5000' | tee -a "$HOME/.bashrc"
    fi

}

update_apt_source() {
    log_debug "run update_apt_source"

    local sources_list="/etc/apt/sources.list"
    local sources_list_d="/etc/apt/sources.list.d"

    if [ -f "$sources_list" ]; then
        sudo cp "$sources_list" "$sources_list.bak_$(date +%Y%m%d%H%M%S)"
        sudo cp -r "$sources_list_d" "$sources_list_d.bak_$(date +%Y%m%d%H%M%S)"

        log_info "å¤‡ä»½ sources.list åˆ° $sources_list.bak_$(date +%Y%m%d%H%M%S)"
        log_info "å¤‡ä»½ sources.list.d åˆ° $sources_list_d.bak_$(date +%Y%m%d%H%M%S)"

        sudo sed -i "s/$OLD_SYS_VERSION/$NEW_SYS_VERSION/g" "$sources_list"
        sudo find /etc/apt/sources.list.d/ -name "*.list" -exec sed -i "s/$OLD_SYS_VERSION/$NEW_SYS_VERSION/g" {} \;
    fi
}

create_user_and_group_nologin() {
    log_debug "run create_user_and_group_nologin"

    local uid=$1  # ç”¨æˆ· id
    local gid=$2  # ç”¨æˆ·ç»„ id
    local name=$3 # ç”¨æˆ·å å’Œ ç”¨æˆ·ç»„å ç›¸åŒ

    if ! getent group "$gid" >/dev/null; then
        sudo groupadd -g "$gid" "$name"
        log_info "åˆ›å»ºä¸ç™»å½•ç”¨æˆ·ç»„: $name, gid: $gid"
    else
        log_warn "ç”¨æˆ·ç»„ gid:$gid å·²ç»å­˜åœ¨"
    fi

    if ! id -u "$uid" >/dev/null 2>&1; then
        sudo useradd -r -M -u "$uid" -g "$gid" "$name"
        sudo usermod -s /sbin/nologin "$name"

        log_info "åˆ›å»ºä¸ç™»å½•ç”¨æˆ·: $name, uid: $uid"
    else
        log_warn "ç”¨æˆ· uid:$uid å·²ç»å­˜åœ¨"
    fi
}

add_group_user() {
    log_debug "run add_group_user"

    create_user_and_group_nologin "$DB_UID" "$DB_GID" "$APP_NAME-database"
    create_user_and_group_nologin "$CLIENT_UID" "$CLIENT_GID" "$APP_NAME-client"
    create_user_and_group_nologin "$SERVER_GID" "$SERVER_GID" "$APP_NAME-server"
    create_user_and_group_nologin "$JPZ_UID" "$JPZ_GID" "$APP_NAME-project"

}

docker_clear_cache() {
    log_debug "run docker_clear_cache"

    sudo docker container prune -f # åˆ é™¤æ‰€æœ‰åœæ­¢çŠ¶æ€çš„å®¹å™¨
    sudo docker network prune -f   # åˆ é™¤æ‰€æœ‰ä¸ä½¿ç”¨çš„ç½‘ç»œ
    sudo docker image prune -f     # åˆ é™¤æ‰€æœ‰ä¸ä½¿ç”¨çš„é•œåƒ
    sudo docker builder prune -f   # åˆ é™¤æ‰€æœ‰ä¸ä½¿ç”¨çš„æ„å»ºç¼“å­˜

    sudo docker images | grep "<none>" | awk '{print $3}' | xargs sudo docker rmi -f || true
}

set_daemon_config() {
    log_debug "run set_daemon_config"

    local target_dir="/etc/docker"
    local target_file="/etc/docker/daemon.json"
    local validate_cmd="sudo dockerd --validate --config-file"

    if [ ! -f "$target_file" ]; then
        log_debug "docker daemon é…ç½®æ–‡ä»¶ä¸å­˜åœ¨, åˆ›å»ºæ–°æ–‡ä»¶"
        sudo mkdir -p "$target_dir"
        echo '{}' | sudo tee "$target_file" >/dev/null
    else
        log_debug "docker daemon é…ç½®æ–‡ä»¶å·²å­˜åœ¨, è¿›è¡Œå¤‡ä»½"
        sudo cp "$target_file" "${target_file}.bak.$(date +%Y%m%d%H%M%S)"
    fi

    local tmp_file="$target_file.tmp"

    cat >"$tmp_file" <<'EOF'
{
  "live-restore": true,
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m",
    "max-file": "7",
    "labels": "production"
  }
EOF

    if [[ $(curl -s --max-time 5 ipinfo.io/country) == "CN" ]]; then
        log_debug "æ£€æµ‹åˆ°å›½å†…ç½‘ç»œç¯å¢ƒ, ä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿ"
        cat >>"$tmp_file" <<'EOF'
  ,
  "registry-mirrors": [
    "https://mirror.ccs.tencentyun.com",
    "https://docker.1ms.run",
    "https://docker.xuanyuan.me"
  ]
EOF
    fi

    cat >>"$tmp_file" <<'EOF'
}
EOF

    if $validate_cmd "$tmp_file" >/dev/null 2>&1; then
        log_debug "docker æ—¥å¿—é…ç½®è¯­æ³•éªŒè¯é€šè¿‡"
    else
        log_error "docker æ—¥å¿—é…ç½®è¯­æ³•éªŒè¯å¤±è´¥, è¯·æ£€æŸ¥ $tmp_file æ–‡ä»¶"
        log_error "æ–‡ä»¶å†…å®¹:"
        sudo cat "$tmp_file"
        sudo rm -f "$tmp_file"
        return 1
    fi

    sudo mv "$tmp_file" "$target_file"

    log_info "docker æ­£åœ¨é‡å¯..."
    sudo systemctl restart docker 2>/dev/null || sudo service docker restart 2>/dev/null

    log_info "å¦‚æœæ‚¨éœ€è¦ä¿®æ”¹é…ç½®, è¯·ç¼–è¾‘ $target_file æ–‡ä»¶å¹¶é‡å¯ docker æœåŠ¡"
}

pull_docker_image_pro_db_billing_center() {
    log_debug "run pull_docker_image_pro_db_billing_center"

    timeout_retry_docker_pull "redis" "$IMG_VERSION_REDIS"
    timeout_retry_docker_pull "postgres" "$IMG_VERSION_PGSQL"

    log_info "docker ç”Ÿäº§ç¯å¢ƒæ•°æ®åº“é•œåƒæ‹‰å–å®Œæˆ"
}

pull_docker_image_pro_all() {
    log_debug "run pull_docker_image_pro_all"

    local has_db
    has_db=$(read_user_input "æ˜¯å¦åŒ…å«æ•°æ®åº“é•œåƒ pgsql redis es (é»˜è®¤y) [y|n]? " "y")

    if [[ "$has_db" == "y" ]]; then
        pull_docker_image_pro_db
    fi

    docker_pull_server
    docker_pull_client
}

__install_docker() {
    log_debug "run __install_docker"

    local is_manual_install="${1-n}"

    docker_install_backup

    local script_url="https://get.docker.com"

    local script_file="./install-docker.sh"

    # shellcheck disable=SC2329
    run() {
        log_debug "ä¸‹è½½å‘½ä»¤: sudo curl -fsSL --connect-timeout 5 --max-time 10 $script_url -o $script_file"
        sudo curl -fsSL --connect-timeout 5 --max-time 10 "$script_url" -o "$script_file"
    }

    if ! retry_with_backoff "run" 5 2 "docker å®‰è£…è„šæœ¬ä¸‹è½½æˆåŠŸ" "docker å®‰è£…è„šæœ¬ä¸‹è½½å¤±è´¥" ""; then
        log_error "ä¸‹è½½ docker å®‰è£…è„šæœ¬å¤±è´¥, è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥"
        exit 1
    fi

    local fastest_docker_mirror
    if [[ "$is_manual_install" == "y" ]]; then
        fastest_docker_mirror=$(manual_select_docker_source)
    else
        fastest_docker_mirror=$(find_fastest_docker_mirror)
    fi

    if [[ -n "$fastest_docker_mirror" ]]; then
        log_info "ä½¿ç”¨æœ€å¿«çš„ Docker CE é•œåƒæº: $fastest_docker_mirror"

        sudo sed -i "s|DOWNLOAD_URL=\"https://mirrors.aliyun.com/docker-ce\"|DOWNLOAD_URL=\"$fastest_docker_mirror\"|g" "$script_file"

        sudo sed -i "s|Aliyun|MyFastMirror|g" "$script_file"
    else
        log_warn "æœªæ‰¾åˆ°å¯ç”¨çš„ Docker CE é•œåƒæº, å°†ä½¿ç”¨é»˜è®¤å®˜æ–¹æºè¿›è¡Œå®‰è£…ï¼Œå¯èƒ½ä¼šå› ä¸ºç½‘ç»œé—®é¢˜å¯¼è‡´å®‰è£…å¤±è´¥"
    fi

    sudo chmod +x "$script_file"

    log_info "æ­£åœ¨å®‰è£… docker, è¯·è€å¿ƒç­‰å¾…..."

    if sudo bash "$script_file" --mirror MyFastMirror 2>&1 | tee -a ./install.log; then
        log_info "docker å®‰è£…è„šæœ¬æ‰§è¡Œå®Œæˆ"

        if command -v docker &>/dev/null && docker --version &>/dev/null; then
            log_info "docker å®‰è£…éªŒè¯æˆåŠŸï¼Œdocker å‘½ä»¤å¯ç”¨"
        else
            log_error "docker å‘½ä»¤ä¸å¯ç”¨ï¼Œå®‰è£…å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®‰è£…æ—¥å¿—"
            return 1
        fi
    else
        log_error "docker å®‰è£…å¤±è´¥"
        return 1
    fi

    log_info "docker å®‰è£…å®Œæˆ, å¼€å§‹è®¾ç½® docker daemon é…ç½®"

    set_daemon_config

    sudo rm -f "$script_file"

    sudo rm -f ./install.log
}

__uninstall_docker() {
    log_debug "run __uninstall_docker"

    sudo systemctl stop docker || true

    sudo apt purge -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin docker-ce-rootless-extras || true

    sudo apt autoremove -y

    log_info "docker å¸è½½å®Œæˆ"

    is_remove=$(read_user_input "æ˜¯å¦éœ€è¦ç§»é™¤ docker çš„å†å²æ•°æ® docker (é»˜è®¤n) [y|n]? " "n")

    if [[ "$is_remove" == "y" ]]; then
        sudo rm -rf /var/lib/docker
        sudo rm -rf /var/lib/containerd

        sudo rm /etc/apt/sources.list.d/docker.list
        sudo rm /etc/apt/keyrings/docker.asc

        log_info "å·²ç§»é™¤ docker å†å²æ•°æ®"
    else
        log_info "æœªç§»é™¤ docker å†å²æ•°æ®"
    fi
}

uninstall_docker() {
    log_debug "run uninstall_docker"

    is_uninstall=$(read_user_input "æ˜¯å¦å¸è½½ docker (é»˜è®¤n) [y|n]? " "n")
    if [[ "$is_uninstall" == "y" ]]; then
        __uninstall_docker
    else
        log_info "æœªå¸è½½ docker"
    fi
}

install_docker() {
    log_debug "run install_docker"
    local is_manual_install="${1-n}"

    if command -v docker >/dev/null 2>&1; then
        log_warn "æ£€æµ‹åˆ°å·²å®‰è£… Docker"

        local is_install
        is_install=$(read_user_input "æ˜¯å¦éœ€è¦å¸è½½åé‡æ–°å®‰è£… docker (é»˜è®¤n) [y|n]? " "n")

        if [[ "$is_install" == "y" ]]; then
            log_debug "å¼€å§‹å¸è½½ docker"

            __uninstall_docker

            __install_docker "$is_manual_install"
        else
            log_info "è·³è¿‡ docker é‡æ–°å®‰è£…æ­¥éª¤"
            return
        fi
    else
        __install_docker
    fi
}

manual_install_docker() {
    log_debug "run manual_install_docker"
    __install_docker "y"
}

DOCKER_CE_TEST_DOWNLOAD_FILE="linux/$(get_docker_repo_path)/gpg" # æµ‹è¯•æ–‡ä»¶è·¯å¾„(ç›¸å¯¹äºé•œåƒæºæ ¹ç›®å½•)

find_fastest_docker_mirror() {
    local temp_dir
    temp_dir=$(mktemp -d)

    trap 'rm -rf "$temp_dir"' EXIT

    declare -A pids_to_sources
    log_info "æ­£åœ¨å¯åŠ¨å¯¹æ‰€æœ‰ Docker CE é•œåƒæºè¿›è¡Œå¹¶å‘æµ‹é€Ÿ..."

    for item in "${DOCKER_CE_SOURCES[@]}"; do
        log_debug "å¯åŠ¨æµ‹è¯•ä»»åŠ¡ for source: $item"
        local source
        IFS='|' read -r source _ <<<"$item"

        local sanitized_source
        sanitized_source="${source//[!a-zA-Z0-9]/_}"
        local output_file="$temp_dir/${sanitized_source}.out"

        (
            trap - EXIT

            local test_url="${source}/${DOCKER_CE_TEST_DOWNLOAD_FILE}"
            local time_total
            time_total=$(curl -s -o /dev/null -w "%{time_total}" --connect-timeout 3 -m 10 "$test_url" 2>/dev/null) || time_total=""

            if [[ "$time_total" =~ ^[0-9]+(\.[0-9]+)?$ ]] && (($(echo "$time_total < 10" | bc -l 2>/dev/null || echo 0))); then
                echo "$time_total $source" >"$output_file"
            else
                echo "FAILED" >"$output_file"
            fi
        ) &

        local pid=$!
        pids_to_sources["$pid"]="$source"

        log_debug "å·²å¯åŠ¨æµ‹è¯•ä»»åŠ¡ PID: $pid -> $source"
    done

    log_debug "æ‰€æœ‰æµ‹è¯•ä»»åŠ¡å·²å¯åŠ¨, å…± ${#pids_to_sources[@]} ä¸ªã€‚æ­£åœ¨ç­‰å¾…é¦–ä¸ªæˆåŠŸå“åº”çš„æº..."

    local fastest_source=""
    local fastest_time=""

    local timeout_counter=0
    local max_timeout=50 # å¤§çº¦10ç§’ (50 * 0.2s)

    while [ ${#pids_to_sources[@]} -gt 0 ] && [ $timeout_counter -lt $max_timeout ]; do
        declare -A completed_this_round # å­˜å‚¨æœ¬è½®å®Œæˆçš„ä»»åŠ¡ PID -> Source
        for pid in "${!pids_to_sources[@]}"; do
            if ! kill -0 "$pid" 2>/dev/null; then
                local source_url="${pids_to_sources[$pid]}"
                local sanitized_source
                sanitized_source="${source_url//[!a-zA-Z0-9]/_}"
                local output_file="$temp_dir/${sanitized_source}.out"

                if [ -f "$output_file" ]; then
                    read -r result <"$output_file"
                    unset "pids_to_sources[$pid]"
                    completed_this_round["$pid"]="$source_url|$result"
                fi
            fi
        done

        if [ ${#completed_this_round[@]} -gt 0 ]; then
            local best_time_in_round=""
            local best_source_in_round=""

            for pid in "${!completed_this_round[@]}"; do
                IFS='|' read -r source_url result <<<"${completed_this_round[$pid]}"

                if [[ "$result" != FAILED* ]]; then
                    used_time=$(echo "$result" | cut -d' ' -f1)

                    if [ -z "$best_time_in_round" ]; then
                        best_time_in_round="$used_time"
                        best_source_in_round=$(echo "$result" | cut -d' ' -f2-)
                    elif (($(echo "$used_time < $best_time_in_round" | bc -l))); then
                        best_time_in_round="$used_time"
                        best_source_in_round=$(echo "$result" | cut -d' ' -f2-)
                    fi
                fi
            done

            if [ -n "$best_source_in_round" ]; then
                fastest_time="$best_time_in_round"
                fastest_source="$best_source_in_round"

                log_debug "ğŸ‰ æ‰¾åˆ°æœ€å¿«çš„ Docker CE é•œåƒæºï¼"
                log_debug "é•œåƒåœ°å€: $fastest_source"
                log_debug "å“åº”æ—¶é—´: $(awk "BEGIN {printf \"%.0f\", $fastest_time * 1000}") ms"

                log_debug "ç»ˆæ­¢å…¶ä»–æ­£åœ¨è¿›è¡Œçš„æµ‹è¯•ä»»åŠ¡..."
                for remaining_pid in "${pids_to_sources[@]}"; do
                    log_debug "ç»ˆæ­¢ä»»åŠ¡ PID: $remaining_pid"

                    sudo kill "$remaining_pid" 2>/dev/null || true
                done
                break 2 # è·³å‡ºå†…å¤–å±‚å¾ªç¯
            fi
        fi

        timeout_counter=$((timeout_counter + 1))
        sleep 0.2 # æ¯200msè½®è¯¢ä¸€æ¬¡
    done

    if [ -z "$fastest_source" ]; then
        log_error "âŒ é”™è¯¯ï¼šåœ¨æŒ‡å®šæ—¶é—´å†…æœªèƒ½æ‰¾åˆ°ä»»ä½•å¯ç”¨çš„ Docker CE é•œåƒæºã€‚"
        log_error "   è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–é•œåƒåˆ—è¡¨ 'DOCKER_CE_SOURCES' æ˜¯å¦æ­£ç¡®ã€‚"
        return 1
    fi

    echo "$fastest_source"
}

docker_install_backup() {
    log_debug "run docker_install_backup"

    local timestamp
    timestamp=$(date +"%Y%m%d_%H%M%S")

    local docker_list_file="/etc/apt/sources.list.d/docker.list"

    if [ -f "$docker_list_file" ]; then
        local bak_dir="/etc/apt/sources.list.d/backup"
        if [ ! -d "$bak_dir" ]; then
            sudo mkdir -p "$bak_dir"
            log_debug "å·²åˆ›å»ºå¤‡ä»½ç›®å½• $bak_dir"
        fi

        sudo cp -a "$docker_list_file" "$bak_dir/docker.list.bak_$timestamp"
        log_info "å·²å¤‡ä»½ $docker_list_file åˆ° $bak_dir/docker.list.bak_$timestamp"

        sudo rm -f "$docker_list_file"
        log_debug "å·²åˆ é™¤ $docker_list_file"
    else
        log_warn "æœªæ‰¾åˆ° $docker_list_fileï¼Œè·³è¿‡å¤‡ä»½å’Œåˆ é™¤"
    fi

    local docker_key_file="/etc/apt/keyrings/docker.asc"
    if [ -f "$docker_key_file" ]; then
        local bak_dir="/etc/apt/keyrings/backup"
        if [ ! -d "$bak_dir" ]; then
            sudo mkdir -p "$bak_dir"
            log_debug "å·²åˆ›å»ºå¤‡ä»½ç›®å½• $bak_dir"
        fi

        sudo cp -a "$docker_key_file" "$bak_dir/docker.asc.bak_$timestamp"
        log_info "å·²å¤‡ä»½ $docker_key_file åˆ° $bak_dir/docker.asc.bak_$timestamp"

        sudo rm -f "$docker_key_file"
        log_debug "å·²åˆ é™¤ $docker_key_file"
    else
        log_warn "æœªæ‰¾åˆ° $docker_key_fileï¼Œè·³è¿‡å¤‡ä»½å’Œåˆ é™¤"
    fi
}

manual_select_docker_source() {
    log_debug "run __install_docker"
    echo "è¯·é€‰æ‹©ä¸€ä¸ª Docker CE é•œåƒæºï¼š" >&2
    for i in "${!DOCKER_CE_SOURCES[@]}"; do
        url="${DOCKER_CE_SOURCES[$i]%|*}"
        name="${DOCKER_CE_SOURCES[$i]#*|}"
        log_debug "é€‰é¡¹ $((i + 1)): $name ($url)"
        printf "%2d) %s\n" $((i + 1)) "$name" >&2
    done

    read -rp "è¯·è¾“å…¥åºå·ï¼ˆ1-${#DOCKER_CE_SOURCES[@]}ï¼‰: " choice

    if [[ ! "$choice" =~ ^[0-9]+$ ]] || [ "$choice" -lt 1 ] || [ "$choice" -gt "${#DOCKER_CE_SOURCES[@]}" ]; then
        log_error "æ— æ•ˆçš„è¾“å…¥ï¼è¯·è¾“å…¥ 1 åˆ° ${#DOCKER_CE_SOURCES[@]} ä¹‹é—´çš„æ•°å­—ã€‚"
        exit 1
    fi

    selected_item="${DOCKER_CE_SOURCES[$((choice - 1))]}"
    url="${selected_item%|*}"

    log_debug "ç”¨æˆ·é€‰æ‹©çš„ Docker CE é•œåƒæº: $url"

    log_info "æ‚¨é€‰æ‹©çš„æ˜¯ï¼š${selected_item#*|}"
    echo "$url"
}

start_db_pgsql_billing_center() {
  log_debug "run start_db_pgsql_billing_center"
  sudo docker compose -f "$DOCKER_COMPOSE_FILE_PGSQL_BILLING_CENTER" -p "$DOCKER_COMPOSE_PROJECT_NAME_PGSQL_BILLING_CENTER" up -d
}

stop_db_pgsql_billing_center() {
  log_debug "run stop_db_pgsql_billing_center"
  sudo docker compose -f "$DOCKER_COMPOSE_FILE_PGSQL_BILLING_CENTER" -p "$DOCKER_COMPOSE_PROJECT_NAME_PGSQL_BILLING_CENTER" down || true
}

restart_db_pgsql_billing_center() {
  log_debug "run restart_db_pgsql_billing_center"
  stop_db_pgsql_billing_center
  start_db_pgsql_billing_center
}

install_db_pgsql_billing_center() {
  log_debug "run install_db_pgsql_billing_center"
  # shellcheck disable=SC2329
  run() {
    local all_remove_data # æ˜¯å¦åˆ é™¤å†å²æ•°æ® é»˜è®¤ä¸åˆ é™¤

    all_remove_data=$(read_user_input "æ˜¯å¦åˆ é™¤ pgsql_billing_center æ•°æ®åº“ä¿¡æ¯(é»˜è®¤n) [y|n]? " "n")

    if [ ! -d "$DATA_VOLUME_DIR" ]; then
      setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$DATA_VOLUME_DIR"
    fi

    setup_directory "$DB_UID" "$DB_GID" 755 "$DATA_VOLUME_DIR/pgsql_billing_center"

    local docker_compose_file="$DOCKER_COMPOSE_FILE_PGSQL_BILLING_CENTER"

    if [ -f "$docker_compose_file" ]; then
      sudo docker compose -f "$docker_compose_file" -p "$DOCKER_COMPOSE_PROJECT_NAME_PGSQL_BILLING_CENTER" down || true # åˆ é™¤å®¹å™¨
      touch "$docker_compose_file"
    fi

    cat >"$docker_compose_file" <<-EOM
services:
  # PostgreSQL æœåŠ¡
  postgres:
    image: 'postgres:$IMG_VERSION_PGSQL'
    container_name: $POSTGRES_DOCKER_NAME_BILLING_CENTER
    restart: always
    user: '$DB_UID:$DB_GID' # DOCKERFILE ä¸­è®¾ç½®çš„ç”¨æˆ·
    environment:
      POSTGRES_USER: $POSTGRES_USER_BILLING_CENTER
      POSTGRES_PASSWORD: $POSTGRES_PASSWORD_BILLING_CENTER
      POSTGRES_DB: $POSTGRES_DB_BILLING_CENTER
      # åˆå§‹åŒ–ä½¿ç”¨å’Œé…ç½®æœ‰æ‰€é‡å¤,éœ€è¦ä¿ç•™ --auth-local=trust æœ¬åœ°è¿æ¥ä¸éœ€è¦å¯†ç   --auth-host=scram-sha-256 è¿œç¨‹è¿æ¥éœ€è¦å¯†ç  --data-checksums æ•°æ®æ ¡éªŒ
      POSTGRES_INITDB_ARGS: "--auth-host=scram-sha-256 --auth-local=trust --data-checksums"

    # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
    command: postgres -c config_file=/etc/postgresql/postgresql.conf -c hba_file=/etc/postgresql/pg_hba.conf

    volumes:
      - $DATA_VOLUME_DIR/pgsql_billing_center/conf/postgresql.conf:/etc/postgresql/postgresql.conf # è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
      - $DATA_VOLUME_DIR/pgsql_billing_center/conf/pg_hba.conf:/etc/postgresql/pg_hba.conf # åœ¨ postgresql.conf é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šè·¯å¾„
      # æ•°æ®ç›®å½•è°ƒæ•´,å‚è€ƒ:https://github.com/docker-library/postgres/pull/1259
      - $DATA_VOLUME_DIR/pgsql_billing_center/data:/var/lib/postgresql/$IMG_VERSION_PGSQL_MAJOR/docker # æ•°æ®å­˜å‚¨ç›®å½•
      - $DATA_VOLUME_DIR/pgsql_billing_center/log:/var/log/postgresql # æ—¥å¿—å­˜å‚¨ç›®å½•

    ports:
      - "$POSTGRES_PORT_BILLING_CENTER:$POSTGRES_PORT_BILLING_CENTER" # æ˜ å°„ç«¯å£

    networks: # ç½‘ç»œé…ç½®
      $BRIDGE_PGSQL_BILLING_CENTER: # ç½‘ç»œåç§°
        ipv4_address: $POSTGRES_IP_BILLING_CENTER # IPåœ°å€

networks: # ç½‘ç»œé…ç½®
  $BRIDGE_PGSQL_BILLING_CENTER: # ç½‘ç»œåç§°
    driver: bridge # ç½‘ç»œé©±åŠ¨
    name: $BRIDGE_PGSQL_BILLING_CENTER # ç½‘ç»œåç§°
    ipam: # IPåœ°å€ç®¡ç†
      config: # IPåœ°å€é…ç½®
        - subnet: "$SUBNET_PGSQL_BILLING_CENTER" # å­ç½‘
          gateway: "$GATEWAY_PGSQL_BILLING_CENTER" # ç½‘å…³
EOM

    if [ "$all_remove_data" == "y" ]; then

      sudo rm -rf "$DATA_VOLUME_DIR/pgsql_billing_center"
      if [ ! -d "$DATA_VOLUME_DIR" ]; then
        setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$DATA_VOLUME_DIR"
      fi

      setup_directory "$DB_UID" "$DB_GID" 755 \
        "$DATA_VOLUME_DIR/pgsql_billing_center" \
        "$DATA_VOLUME_DIR/pgsql_billing_center/data" \
        "$DATA_VOLUME_DIR/pgsql_billing_center/conf" \
        "$DATA_VOLUME_DIR/pgsql_billing_center/log"

      local content_postgresql_conf
      local content_pg_hba_conf

      content_postgresql_conf=$(get_content_postgresql_conf "$POSTGRES_PORT_BILLING_CENTER")
      content_pg_hba_conf=$(get_content_pg_hba_conf "$SUBNET_PGSQL_BILLING_CENTER" "$SUBNET_BILLING_CENTER")

      over_write_set_owner "$DB_UID" "$DB_GID" 600 "$content_postgresql_conf" "$DATA_VOLUME_DIR/pgsql_billing_center/conf/postgresql.conf"
      over_write_set_owner "$DB_UID" "$DB_GID" 600 "$content_pg_hba_conf" "$DATA_VOLUME_DIR/pgsql_billing_center/conf/pg_hba.conf"

      log_info "å·²åˆ é™¤ pgsql_billing_center å†å²æ•°æ®"

    else
      log_info "æœªåˆ é™¤ pgsql_billing_center å†å²æ•°æ®"
    fi

    start_db_pgsql_billing_center

  }

  log_timer "pgsql_billing_center å¯åŠ¨" run

  log_info "pgsql_billing_center å®‰è£…å®Œæˆ, è¯·ä½¿ç”¨ sudo docker ps -a æŸ¥çœ‹å®¹å™¨æ˜ç»†"
}

delete_db_pgsql_billing_center() {
  log_debug "run delete_db_pgsql_billing_center"

  local is_delete
  is_delete=$(read_user_input "ç¡®è®¤åœæ­¢ pgsql_billing_center æœåŠ¡å¹¶åˆ é™¤æ•°æ®å—(é»˜è®¤n) [y|n] " "n")

  if [[ "$is_delete" == "y" ]]; then
    stop_db_pgsql_billing_center

    sudo rm -rf "$DATA_VOLUME_DIR/pgsql_billing_center"
  fi
}

get_content_postgresql_conf() {
  local postgres_port=$1

  local content_postgresql_conf
  content_postgresql_conf=$(
    cat <<EOL
# PostgreSQL é…ç½®æ–‡ä»¶

# é…ç½®ç›®å½•: /etc/postgresql
# æ•°æ®ç›®å½•: /var/lib/postgresql

# è¿æ¥è®¾ç½®
listen_addresses = '*'                             # ç›‘å¬åœ°å€,'*'ä¸ºç›‘å¬æ‰€æœ‰IP
port = $postgres_port                              # ç›‘å¬ç«¯å£
max_connections = 200                              # æœ€å¤§è¿æ¥æ•°
superuser_reserved_connections = 3                 # è¶…çº§ç”¨æˆ·ä¿ç•™è¿æ¥æ•°
ssl = off                                          # SSLåŠ å¯†

# è®¤è¯è®¾ç½®
password_encryption = scram-sha-256                # å¯†ç åŠ å¯†æ–¹æ³• (scram-sha-256 or md5)

# å†…å­˜å‚æ•°è®¾ç½®
shared_buffers = 256MB                             # å…±äº«ç¼“å†²åŒºå¤§å°
effective_cache_size = 256MB                       # å·¥ä½œå†…å­˜å¤§å°
maintenance_work_mem = 64MB                        # ç»´æŠ¤å·¥ä½œå†…å­˜å¤§å°
temp_buffers = 8MB                                 # ä¸´æ—¶ç¼“å†²åŒºå¤§å°
dynamic_shared_memory_type = posix                 # åŠ¨æ€å…±äº«å†…å­˜ç±»å‹ (posix, sysv, windows, mmap)

# å†™å…¥å‚æ•°è®¾ç½®
fsync = on                                         # åŒæ­¥ç£ç›˜å†™å…¥
wal_sync_method = fsync                            # WALåŒæ­¥æ–¹æ³•
synchronous_commit = on                            # åŒæ­¥æäº¤
checkpoint_timeout = 5min                          # æ£€æŸ¥ç‚¹è¶…æ—¶æ—¶é—´
checkpoint_completion_target = 0.9                 # æ£€æŸ¥ç‚¹å®Œæˆç›®æ ‡ç™¾åˆ†æ¯”
checkpoint_flush_after = 32kB                      # æ£€æŸ¥ç‚¹åˆ·æ–°é—´éš”å¤§å°

# ç£ç›˜å‚æ•°è®¾ç½®
max_wal_size = 1GB                                 # WALæ—¥å¿—æ–‡ä»¶æœ€å¤§å¤§å°
min_wal_size = 80MB                                # WALæ—¥å¿—æ–‡ä»¶æœ€å°å¤§å°

timezone = 'Asia/Shanghai'                         # æ—¶åŒºè®¾ç½® (UTC, Asia/Shanghai, Etc/UTC)

# æ—¥å¿—è®¾ç½®
log_destination = 'stderr'                         # æ—¥å¿—è¾“å‡ºç›®æ ‡
logging_collector = on                             # å¯ç”¨æ—¥å¿—æ”¶é›†
log_directory = 'pg_log'                           # æ—¥å¿—ç›®å½•
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'    # æ—¥å¿—æ–‡ä»¶å
log_truncate_on_rotation = on                      # æˆªæ–­æ—§æ—¥å¿—
log_rotation_age = 7d                              # æ—¥å¿—è½®æ¢æ—¶é—´
log_rotation_size = 10MB                           # æ—¥å¿—è½®æ¢å¤§å°
log_min_duration_statement = -1                    # è®°å½•æ…¢æŸ¥è¯¢é˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰
log_line_prefix = '%t [%p]: [%x] %u@%d %i '        # æ—¥å¿—è¡Œå‰ç¼€æ ¼å¼
log_timezone = 'Asia/Shanghai'                     # æ—¥å¿—æ—¶åŒº

# è¿è¡Œæ—¶ç»Ÿè®¡ä¿¡æ¯è®¾ç½®
track_activities = on                              # ä¸è¸ªè¿æ¥æ´»åŠ¨
track_counts = on                                  # ä¸è¸ªå¯¹è±¡æ•°é‡
update_process_title = on                          # æ›´æ–°è¿›ç¨‹æ ‡é¢˜æ˜¾ç¤ºçŠ¶æ€

# å…¶ä»–å‚æ•°
datestyle = 'iso, mdy'                             # æ—¥æœŸè¾“å‡ºæ ¼å¼
lc_messages='en_US.UTF-8'                          # æœ¬åœ°åŒ–æ¶ˆæ¯æ˜¾ç¤ºè®¾ç½®
lc_monetary='en_US.UTF-8'                          # æœ¬åœ°åŒ–è´§å¸æ˜¾ç¤ºè®¾ç½®
lc_numeric='en_US.UTF-8'                           # æœ¬åœ°åŒ–æ•°å­—æ˜¾ç¤ºè®¾ç½®
lc_time='en_US.UTF-8'                              # æœ¬åœ°åŒ–æ—¶é—´æ˜¾ç¤ºè®¾ç½®
default_text_search_config = 'pg_catalog.english'  # é»˜è®¤å…¨æ–‡æœç´¢é…ç½®
EOL
  )

  echo "$content_postgresql_conf"
}

get_content_pg_hba_conf() {
  local subnet_pgsql=$1
  local subnet_server=$2

  local content_pg_hba_conf
  content_pg_hba_conf=$(
    cat <<EOL
# PostgreSQL Client Authentication Configuration File
# ===================================================

# TYPE  DATABASE        USER            ADDRESS                 METHOD

# "local" is for Unix domain socket connections only
local   all             all                                     trust

# Allow replication connections from localhost, by a user with the
# replication privilege.
local   replication     all                                     trust

# ip4è®¿é—®æƒé™é™åˆ¶å¼€å§‹
#host    all             all             10.0.0.0/16         scram-sha-256 # å…è®¸æ­¤ IP åœ°å€è®¿é—®
#host    all             all             $subnet_pgsql        scram-sha-256 # å…è®¸æ­¤ IP åœ°å€è®¿é—®
#host    all             all             $subnet_server        scram-sha-256 # å…è®¸æ­¤ IP åœ°å€è®¿é—®
#host    all             all             $HOST_INTRANET_IP/$(get_cidr "$HOST_INTRANET_MARK")        scram-sha-256 # å…è®¸æ­¤ IP åœ°å€è®¿é—®
# ip4è®¿é—®æƒé™é™åˆ¶ç»“æŸ

# ip4è®¿é—®æƒé™æ”¾å¼€å¼€å§‹
host    all             all             0.0.0.0/0               scram-sha-256 # å…è®¸æ‰€æœ‰ ip4 è®¿é—®
# ip4è®¿é—®æƒé™æ”¾å¼€ç»“æŸ

# ip6 è®¿é—®æƒé™
# host    all             all             ::/0                    scram-sha-256
EOL
  )
  echo "$content_pg_hba_conf"
}

start_db_pgsql() {
  log_debug "run start_db_pgsql"
  sudo docker compose -f "$DOCKER_COMPOSE_FILE_PGSQL" -p "$DOCKER_COMPOSE_PROJECT_NAME_PGSQL" up -d
}

stop_db_pgsql() {
  log_debug "run stop_db_pgsql"
  sudo docker compose -f "$DOCKER_COMPOSE_FILE_PGSQL" -p "$DOCKER_COMPOSE_PROJECT_NAME_PGSQL" down || true
}

restart_db_pgsql() {
  log_debug "run restart_db_pgsql"
  stop_db_pgsql
  start_db_pgsql
}

toggle_pg_hba_conf() {
  log_debug "run toggle_pg_hba_conf"

  local mode="$1"
  local file_path="$2"

  if [[ "$mode" == "restrict" ]]; then
    sudo awk '/# ip4è®¿é—®æƒé™é™åˆ¶å¼€å§‹/,/# ip4è®¿é—®æƒé™é™åˆ¶ç»“æŸ/ {sub(/^#host/, "host"); print; next} 1' "$file_path" | sudo tee temp >/dev/null && sudo mv temp "$file_path"
    sudo awk '/# ip4è®¿é—®æƒé™æ”¾å¼€å¼€å§‹/,/# ip4è®¿é—®æƒé™æ”¾å¼€ç»“æŸ/ {sub(/^host/, "#host"); print; next} 1' "$file_path" | sudo tee temp >/dev/null && sudo mv temp "$file_path"
  elif [[ "$mode" == "open" ]]; then
    sudo awk '/# ip4è®¿é—®æƒé™é™åˆ¶å¼€å§‹/,/# ip4è®¿é—®æƒé™é™åˆ¶ç»“æŸ/ {sub(/^#host/, "#host"); print; next} 1' "$file_path" | sudo tee temp >/dev/null && sudo mv temp "$file_path"
    sudo awk '/# ip4è®¿é—®æƒé™æ”¾å¼€å¼€å§‹/,/# ip4è®¿é—®æƒé™æ”¾å¼€ç»“æŸ/ {sub(/^#host/, "host"); print; next} 1' "$file_path" | sudo tee temp >/dev/null && sudo mv temp "$file_path"
  else
    log_error "åˆ‡æ¢ pg_hba.conf è®¿é—®æƒé™å¤±è´¥, æ¨¡å¼é”™è¯¯: $mode; åªèƒ½æ˜¯ restrict æˆ– open"
    return 1
  fi

  log_info "$file_path å·²ç»åˆ‡æ¢ $mode æ¨¡å¼."
}

open_pgsql_access_by_pg_hba.conf() {
  log_debug "run open_pgsql_access_by_pg_hba.conf"

  sudo docker stop "$POSTGRES_DOCKER_NAME"                          # åœæ­¢å®¹å™¨ pgsql å®¹å™¨
  toggle_pg_hba_conf open "$DATA_VOLUME_DIR/pgsql/conf/pg_hba.conf" # åˆ‡æ¢è®¿é—®æƒé™
  sudo docker start "$POSTGRES_DOCKER_NAME"                         # é‡å¯å®¹å™¨
}

restrict_pgsql_access_by_pg_hba.conf() {
  log_debug "run restrict_pgsql_access_by_pg_hba.conf"

  sudo docker stop "$POSTGRES_DOCKER_NAME"                              # åœæ­¢å®¹å™¨ pgsql å®¹å™¨
  toggle_pg_hba_conf restrict "$DATA_VOLUME_DIR/pgsql/conf/pg_hba.conf" # åˆ‡æ¢è®¿é—®æƒé™
  sudo docker start "$POSTGRES_DOCKER_NAME"                             # é‡å¯å®¹å™¨
}

start_db_redis_billing_center() {
    log_debug "run start_db_redis_billing_center"
    sudo docker compose -f "$DOCKER_COMPOSE_FILE_REDIS_BILLING_CENTER" -p "$DOCKER_COMPOSE_PROJECT_NAME_REDIS_BILLING_CENTER" up -d # å¯åŠ¨å®¹å™¨
}

stop_db_redis_billing_center() {
    log_debug "run stop_db_redis_billing_center"
    sudo docker compose -f "$DOCKER_COMPOSE_FILE_REDIS_BILLING_CENTER" -p "$DOCKER_COMPOSE_PROJECT_NAME_REDIS_BILLING_CENTER" down || true
}

restart_db_redis_billing_center() {
    log_debug "run restart_db_redis_billing_center"
    stop_db_redis_billing_center
    start_db_redis_billing_center
}

install_db_redis_billing_center() {
    log_debug "run install_db_redis_billing_center"
    # shellcheck disable=SC2329
    run() {
        local is_redis_cluster # æ˜¯å¦åˆ›å»º redis é›†ç¾¤ é»˜è®¤ä¸åˆ›å»º
        local all_remove_data  # æ˜¯å¦åˆ é™¤å†å²æ•°æ® é»˜è®¤ä¸åˆ é™¤

        is_redis_cluster=$(read_user_input "[1/2]æ˜¯å¦åˆ›å»º redis_billing_center é›†ç¾¤(é»˜è®¤n) [y|n]? " "n")
        all_remove_data=$(read_user_input "[2/2]æ˜¯å¦åˆ é™¤ redis_billing_center (é»˜è®¤n) [y|n]? " "n")

        if [ ! -d "$DATA_VOLUME_DIR" ]; then
            setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$DATA_VOLUME_DIR"
        fi

        setup_directory "$DB_UID" "$DB_GID" 755 "$DATA_VOLUME_DIR/redis_billing_center"

        local docker_compose_file="$DOCKER_COMPOSE_FILE_REDIS_BILLING_CENTER"

        if [ -f "$docker_compose_file" ]; then
            sudo docker compose -f "$docker_compose_file" -p "$DOCKER_COMPOSE_PROJECT_NAME_REDIS_BILLING_CENTER" down || true # åˆ é™¤å®¹å™¨
            touch "$docker_compose_file"
        fi
        cat >"$docker_compose_file" <<-EOM
services:
EOM

        if [ "$is_redis_cluster" == "n" ]; then
            MASTER_COUNT=1
            SLAVE_COUNT=0
        fi

        cluster_urls="" # é›†ç¾¤èŠ‚ç‚¹åœ°å€
        redis_ips=""    # ipåœ°å€æ‹¼æ¥
        for ((port = REDIS_BASE_PORT_BILLING_CENTER; port < REDIS_BASE_PORT_BILLING_CENTER + MASTER_COUNT + SLAVE_COUNT; port++)); do
            port_cluster=$((port + 10000))                                                                   # port_cluster è‡ªå¢ é›†ç¾¤ç›‘æ§ç«¯å£
            ip_node="$IPV4_BASE_REDIS_BILLING_CENTER.$(((port - REDIS_BASE_PORT_BILLING_CENTER + 2) % 256))" # ip_node è‡ªå¢ ä» 2 å¼€å§‹, 1 ä¸ºç½‘å…³

            cluster_urls+="redis-$IMG_VERSION_REDIS-$port:$port " # é›†ç¾¤èŠ‚ç‚¹ åç§°
            redis_ips+="$ip_node "                                # é›†ç¾¤èŠ‚ç‚¹åœ°å€

            cat >>"$docker_compose_file" <<-EOM

  redis-$IMG_VERSION_REDIS-$port:
    image: 'redis:$IMG_VERSION_REDIS'
    restart: always
    container_name: redis-$IMG_VERSION_REDIS-$port
    user: '$DB_UID:$DB_GID' # DOCKERFILE ä¸­è®¾ç½®çš„ç”¨æˆ·
    volumes:
      - $DATA_VOLUME_DIR/redis_billing_center/data/$port:/data
      - $DATA_VOLUME_DIR/redis_billing_center/conf/$port:/usr/local/etc/redis # é…ç½®æ–‡ä»¶éœ€è¦æŒ‡å®šæ–‡ä»¶å¤¹å¦åˆ™ä¼šæ— æ³•å†™å…¥
      - $DATA_VOLUME_DIR/redis_billing_center/log/$port:/var/log/redis

    command: [/usr/local/etc/redis/redis.conf] # æŒ‡å®šé…ç½®æ–‡ä»¶é‡æ–°åŠ è½½

    ports: # æ˜ å°„ç«¯å£ï¼Œå¯¹å¤–æä¾›æœåŠ¡
      - "$port:$port" # redis çš„æœåŠ¡ç«¯å£
      - "$port_cluster:$port_cluster" # redis é›†ç¾¤ç›‘æ§ç«¯å£
    # stdin_open: true # æ ‡å‡†è¾“å…¥æ‰“å¼€
    # tty: true # ç»ˆç«¯æ‰“å¼€
    # privileged: true # æ‹¥æœ‰å®¹å™¨å†…å‘½ä»¤æ‰§è¡Œçš„æƒé™

    networks: # docker ç½‘ç»œè®¾ç½®
      $BRIDGE_REDIS_BILLING_CENTER: # ç½‘ç»œåç§°
          ipv4_address: $ip_node
EOM
        done

        if [ "$all_remove_data" == "y" ]; then

            sudo rm -rf "$DATA_VOLUME_DIR/redis_billing_center"
            if [ ! -d "$DATA_VOLUME_DIR" ]; then
                setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$DATA_VOLUME_DIR"
            fi

            setup_directory "$DB_UID" "$DB_GID" 755 \
                "$DATA_VOLUME_DIR/redis_billing_center" \
                "$DATA_VOLUME_DIR/redis_billing_center/data" \
                "$DATA_VOLUME_DIR/redis_billing_center/conf" \
                "$DATA_VOLUME_DIR/redis_billing_center/log"

            for ((port = REDIS_BASE_PORT_BILLING_CENTER; port < REDIS_BASE_PORT_BILLING_CENTER + MASTER_COUNT + SLAVE_COUNT; port++)); do

                ip_node="$IPV4_BASE_REDIS_BILLING_CENTER.$(((port - REDIS_BASE_PORT_BILLING_CENTER + 2) % 256))" # ip_node è‡ªå¢ ä» 2 å¼€å§‹, 1 ä¸ºç½‘å…³
                setup_directory "$DB_UID" "$DB_GID" 755 \
                    "$DATA_VOLUME_DIR/redis_billing_center/data/$port" \
                    "$DATA_VOLUME_DIR/redis_billing_center/conf/$port" \
                    "$DATA_VOLUME_DIR/redis_billing_center/log/$port"

                config_cluster=""

                if [ "${is_redis_cluster,,}" = "y" ]; then
                    config_cluster=$(
                        cat <<EOF
### å¤åˆ¶ï¼ˆä¸»ä»åŒæ­¥ï¼‰
# æ˜¯å¦ä¸ºå¤åˆ¶åªè¯»
slave-read-only yes

# ä¸»èŠ‚ç‚¹ å¯†ç 
masterauth "$REDIS_PASSWORD_BILLING_CENTER"

### é›†ç¾¤é…ç½®
# å¼€å¯é›†ç¾¤æ¨¡å¼è‡³å°‘ä¸‰ä¸ªä¸»èŠ‚ç‚¹
cluster-enabled yes
cluster-config-file nodes.conf
cluster-node-timeout 15000

# #######CLUSTER DOCKER/NAT support#######
# é›†ç¾¤å’Œå“¨å…µä¸èƒ½ä½¿ç”¨ docker çš„ NAT æ¨¡å¼ ä½¿ç”¨ host æ¨¡å¼
# å‚è€ƒ:https://redis.io/docs/latest/operate/oss_and_stack/management/sentinel/
# cluster-announce-ip redis-$IMG_VERSION_REDIS-$port
# cluster-announce-ip $HOST_INTRANET_IP

cluster-announce-ip $ip_node
cluster-announce-port $port
cluster-announce-bus-port 1$port
EOF
                    )

                fi

                content=$(
                    cat <<EOL
# Redis é…ç½®æ–‡ä»¶
######################

### ä¸€èˆ¬è®¾ç½®
# ç»‘å®š IP (é»˜è®¤æƒ…å†µä¸‹,Redis åªå…è®¸æœ¬åœ°è¿æ¥)
# bind 127.0.0.1 $ip_node
# bind 127.0.0.1
bind 0.0.0.0

# Redis ç›‘å¬ç«¯å£ (é»˜è®¤ä¸º 6379)
port $port

# å¯ç”¨ä¿æŠ¤æ¨¡å¼:no, å…³é—­ docker å¤–éƒ¨æ‰èƒ½è®¿é—®ã€‚
protected-mode no

# è®¾ç½®å¯†ç 
requirepass "$REDIS_PASSWORD_BILLING_CENTER"

### å®¢æˆ·ç«¯è®¾ç½®
# å®¢æˆ·ç«¯ç©ºé—²è¶…æ—¶æ—¶é—´(å•ä½:ç§’),è®¾ç½®æˆ 0 åˆ™è¡¨ç¤ºä¸é™åˆ¶å®¢æˆ·ç«¯ç©ºé—²æ—¶é—´
timeout 0

# æœ€å¤§å®¢æˆ·ç«¯è¿æ¥æ•°,é»˜è®¤ä¸º 10000
maxclients 10000

### æ•°æ®å­˜å‚¨
# æŒ‡å®šæ•°æ®æ–‡ä»¶å­˜æ”¾ç›®å½•
dir ./

# å¦‚æœè‡³å°‘æœ‰ 1 ä¸ª key åœ¨ 900 ç§’å†…è¢«ä¿®æ”¹äº†,åˆ™ç”Ÿæˆ RDB æ–‡ä»¶
save 900 1

# å¦‚æœè‡³å°‘æœ‰ 10 ä¸ª key åœ¨ 300 ç§’å†…è¢«ä¿®æ”¹äº†,åˆ™ç”Ÿæˆ RDB æ–‡ä»¶
save 300 10

# å¦‚æœè‡³å°‘æœ‰ 10000 ä¸ª key åœ¨ 60 ç§’å†…è¢«ä¿®æ”¹äº†,åˆ™ç”Ÿæˆ RDB æ–‡ä»¶
save 60 10000

# RDB æ–‡ä»¶åç§°
dbfilename dump.rdb

# æ˜¯å¦å¯ç”¨ RDB æ–‡ä»¶å‹ç¼©
rdbcompression yes

# æ˜¯å¦ä½¿ç”¨ CRC64 æ ¡éªŒ RDB æ–‡ä»¶
rdbchecksum yes

### AOF 
# å¯ç”¨ AOF æŒä¹…åŒ–
appendonly yes

# AOF å†å²ç­–ç•¥
appendfsync everysec

# AOF æ–‡ä»¶åç§°
appendfilename "appendonly.aof"

# æ˜¯å¦é‡å†™ AOF æ–‡ä»¶
auto-aof-rewrite-min-size 64mb
auto-aof-rewrite-percentage 100

### æ—¥å¿—è®°å½•
# æ—¥å¿—ç­‰çº§
loglevel notice

# æ—¥å¿—è¾“å‡ºç±»å‹
logfile /var/log/redis/redis-server.log

### ç³»ç»Ÿèµ„æºé™åˆ¶
# TCP backlog,æ ¹æ®æŒ‡å®šçš„æ•°é‡æ¥æ§åˆ¶ TCP è¿æ¥æ•°
tcp-backlog 511

### å†…å­˜ç®¡ç†
# Redis æœ€å¤§ä½¿ç”¨å†…å­˜
# maxmemory 0

# Redis å†…å­˜å›æ”¶ç­–ç•¥
maxmemory-policy volatile-lru

# æŒ‡å®šå†…å­˜æ ·æœ¬å¤§å°
maxmemory-samples 5

$config_cluster

# ####### CLUSTER DOCKER/NAT support #######

### å…¶ä»–é…ç½®
# æ•°æ®åº“ index é»˜è®¤ä¸º 0
# databases 0

EOL
                )

                over_write_set_owner "$DB_UID" "$DB_GID" 600 "$content" "$DATA_VOLUME_DIR/redis_billing_center/conf/$port/redis.conf"
            done

            log_info "å·²åˆ é™¤ redis_billing_center å†å²æ•°æ®"
        else
            log_info "æœªåˆ é™¤ redis_billing_center å†å²æ•°æ®"
        fi

        cat >>"$docker_compose_file" <<-EOM
networks: # ç½‘ç»œé…ç½®
  $BRIDGE_REDIS_BILLING_CENTER: # ç½‘ç»œåç§°
    driver: bridge # ç½‘ç»œé©±åŠ¨
    name: $BRIDGE_REDIS_BILLING_CENTER # ç½‘ç»œåç§°
    ipam: # IPåœ°å€ç®¡ç†
      config: # IPåœ°å€é…ç½®
        - subnet: "$SUBNET_REDIS_BILLING_CENTER" # å­ç½‘
          gateway: "$GATEWAY_REDIS_BILLING_CENTER" # ç½‘å…³
EOM
        start_db_redis_billing_center

        if [ "$all_remove_data" == "y" ] && [ "$is_redis_cluster" = "y" ]; then
            log_info "redis é›†ç¾¤å¼€å¯"
            redis_name="redis-$IMG_VERSION_REDIS-$REDIS_BASE_PORT_BILLING_CENTER"
            REDIS_CLI_COMMAND="echo yes | redis-cli -h $redis_name -p $REDIS_BASE_PORT_BILLING_CENTER -a $REDIS_PASSWORD_BILLING_CENTER --cluster-replicas 1 --cluster create $cluster_urls"

            log_debug "æ‰§è¡Œå‘½ä»¤: sudo docker exec -it $redis_name /bin/bash -c \"$REDIS_CLI_COMMAND\""

            sudo docker exec -i "$redis_name" /bin/bash -c "$REDIS_CLI_COMMAND"
            log_info "redis é›†ç¾¤åˆ›å»ºå®Œæˆ"
        fi
    }

    log_timer "redis å¯åŠ¨å®Œæ¯•" run

    log_info "redis_billing_center å®‰è£…å®Œæˆ, è¯·ä½¿ç”¨ sudo docker ps -a æŸ¥çœ‹å®¹å™¨æ˜ç»†"
}

delete_db_redis_billing_center() {
    log_debug "run delete_db_redis_billing_center"

    local is_delete
    is_delete=$(read_user_input "ç¡®è®¤åœæ­¢ redis_billing_center æœåŠ¡å¹¶åˆ é™¤æ•°æ®å—(é»˜è®¤n) [y|n]? " "n")

    if [[ "$is_delete" == "y" ]]; then
        stop_db_redis_billing_center

        sudo rm -rf "$DATA_VOLUME_DIR/redis_billing_center"
    fi
}

billing_center_cli() {
  log_debug "run billing_center_cli"

  local arg=$1

  log_debug "æ‰§è¡Œå‘½ä»¤: sudo docker exec -it billing-center /bin/sh -c \"/home/billing-center/billing-center ${arg}\""

  sudo docker exec -it billing-center /bin/sh -c "/home/billing-center/billing-center ${arg}"

}

ca_cert_byte_print() {
  log_debug "run ca-cert-byte-print"
  billing_center_cli "ca-cert-byte-print -n 32"
}

create_docker_compose_billing_center() {
  log_debug "run create_docker_compose_billing_center"

  local version="${1:-latest}"

  local docker_compose_file="$DOCKER_COMPOSE_FILE_BILLING_CENTER"
  if [ -f "$docker_compose_file" ]; then
    sudo rm -f "$docker_compose_file"
  fi

  local img_prefix
  img_prefix=$(get_img_prefix)

  cat >"$docker_compose_file" <<-EOM
# è¿è¡Œå‘½ä»¤:sudo docker compose -f $docker_compose_file -p "$DOCKER_COMPOSE_PROJECT_NAME_BILLING_CENTER" up -d

services:
  billing-center:
    image: $img_prefix/billing-center:$version
    restart: always
    container_name: billing-center
    user: '$JPZ_UID:$JPZ_GID' # DOCKERFILE ä¸­è®¾ç½®çš„ç”¨æˆ·
    volumes:
      - $DATA_VOLUME_DIR/billing-center/config:/home/billing-center/config
      - $DATA_VOLUME_DIR/billing-center/logs:/home/billing-center/logs
      - $DATA_VOLUME_DIR/billing-center/nginx:/etc/nginx
    ports:
      - '80:80' # http ç«¯å£
      - '443:443' # https ç«¯å£
    networks: # docker ç½‘ç»œè®¾ç½®
      $BRIDGE_BILLING_CENTER: # ç½‘ç»œåç§°
        ipv4_address: $IPV4_BASE_BILLING_CENTER.2 # IPåœ°å€
    
    # å¥åº·æ£€æŸ¥
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -sk https://localhost/api/v1/helper/version | grep 'request_id'",
        ]
      interval: 10s
      timeout: 10s
      retries: 120

networks: # ç½‘ç»œé…ç½®
  $BRIDGE_BILLING_CENTER: # ç½‘ç»œåç§°
    driver: bridge # ç½‘ç»œé©±åŠ¨
    name: $BRIDGE_BILLING_CENTER # ç½‘ç»œåç§°
    ipam: # IPåœ°å€ç®¡ç†
      config: # IPåœ°å€é…ç½®
        - subnet: "$SUBNET_BILLING_CENTER" # å­ç½‘
          gateway: "$GATEWAY_BILLING_CENTER" # ç½‘å…³
EOM

  log_info "$docker_compose_file create success"
}

copy_billing_center_nginx_config() {

    log_debug "run copy_billing_center_nginx_config"

    dir_billing_center="$DATA_VOLUME_DIR/billing-center/nginx"

    sudo rm -rf "$dir_billing_center"

    # shellcheck disable=SC2329
    run_copy_config() {
        sudo docker cp temp_container_blog_billing_center:/etc/nginx "$DATA_VOLUME_DIR/billing-center" # å¤åˆ¶é…ç½®æ–‡ä»¶
    }

    docker_create_billing_center_temp_container run_copy_config "latest"

    if [ ! -d "$CERTS_NGINX" ]; then
        echo "========================================"
        echo "    è¯·å°†è¯ä¹¦ $CERTS_NGINX æ–‡ä»¶å¤¹æ”¾åˆ°å½“å‰ç›®å½•"
        echo "    è¯ä¹¦æ–‡ä»¶å¤¹ç»“æ„å¦‚ä¸‹:"
        echo "    $CERTS_NGINX"
        echo "    â”œâ”€â”€ cert.key"
        echo "    â””â”€â”€ cert.pem"
        echo "========================================"
        log_error "è¯·å°†è¯ä¹¦ $CERTS_NGINX æ–‡ä»¶å¤¹æ”¾åˆ°å½“å‰ç›®å½•"
        exit 1
    fi

    if [ ! -d "$DATA_VOLUME_DIR" ]; then
        setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$DATA_VOLUME_DIR"
    fi

    setup_directory "$JPZ_UID" "$JPZ_GID" 755 \
        "$DATA_VOLUME_DIR/billing-center" \
        "$DATA_VOLUME_DIR/billing-center/nginx" \
        "$DATA_VOLUME_DIR/billing-center/nginx/ssl"

    if [ -z "$(ls -A "$CERTS_NGINX")" ]; then
        log_error "è¯ä¹¦ç›®å½• $CERTS_NGINX ä¸ºç©º, è¯·æ·»åŠ è¯ä¹¦æ–‡ä»¶"

        ssl_msg "$RED"
        exit 1
    fi

    sudo cp -r "$CERTS_NGINX"/* "$DATA_VOLUME_DIR/billing-center/nginx/ssl/"

    setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$DATA_VOLUME_DIR/billing-center/nginx/ssl/"

    log_info "billing-center å¤åˆ¶ nginx é…ç½®æ–‡ä»¶åˆ° volume success"
}

server_update_password_key_billing_center() {
    log_debug "run server_update_password_key_billing_center"

    local config_dir="$DATA_VOLUME_DIR/billing-center/config"

    sudo sed -i "s%password:[[:space:]]*\"[^\"]*\"%password: \"$POSTGRES_PASSWORD_BILLING_CENTER\"%" "$config_dir/pgsql.yaml"

    sudo sed -i "s%password:[[:space:]]*\"[^\"]*\"%password: \"$REDIS_PASSWORD_BILLING_CENTER\"%" "$config_dir/redis.yaml"

    log_info "billing-center æ›´æ–°æ•°æ®åº“å¯†ç é…ç½® success"
}

copy_billing_center_server_config() {

    log_debug "run copy_billing_center_server_config"

    dir_billing_center="$DATA_VOLUME_DIR/billing-center/config"

    sudo rm -rf "$dir_billing_center"

    if [ ! -d "./bc-config" ]; then
        local msg=""
        msg+="\nè¯·å°† billing_center é…ç½®æ–‡ä»¶å‡†å¤‡å¥½å¹¶æ”¾ç½®åˆ°ä»¥ä¸‹ç›®å½•: "
        msg+="\n    ./bc-config (é…ç½®æ–‡ä»¶)"
        msg+="\n"
        log_warn "$msg"
        log_warn "bc-config ç›®å½•ä¸å­˜åœ¨, è¯·å…ˆå‡†å¤‡å¥½é…ç½®æ–‡ä»¶åå†è¿›è¡Œå…¨æ–°å®‰è£…"
        exit 1
    fi

    cp -r "./bc-config/" "$DATA_VOLUME_DIR/billing-center/config/"

    server_update_password_key_billing_center

    if [ ! -d "$DATA_VOLUME_DIR" ]; then
        setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$DATA_VOLUME_DIR"
    fi

    setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$DATA_VOLUME_DIR/billing-center/config/"

    log_info "billing-center å¤åˆ¶åç«¯é…ç½®æ–‡ä»¶åˆ° volume success"
}

docker_rmi_billing_center() {
    log_debug "run docker_rmi_billing_center"

    local is_delete
    is_delete=$(read_user_input "ç¡®è®¤åœæ­¢ billing_center æœåŠ¡å¹¶åˆ é™¤é•œåƒå—(é»˜è®¤n) [y|n]? " "n")

    if [[ "$is_delete" == "y" ]]; then
        docker_billing_center_stop

        log_debug "æ‰§è¡Œçš„å‘½ä»¤ï¼šsudo docker images --format \"table {{.Repository}}\t{{.Tag}}\t{{.ID}}\" | grep billing-center | awk '{print \$3}' | xargs sudo docker rmi -f"

        sudo docker images --format "table {{.Repository}}\t{{.Tag}}\t{{.ID}}" | grep billing-center | awk '{print $3}' | xargs sudo docker rmi -f

        log_info "åˆ é™¤ billing_center é•œåƒå®Œæˆ, è¯·ä½¿ç”¨ sudo docker images æŸ¥çœ‹é•œåƒæ˜ç»†"
    fi
}

mkdir_billing_center_volume() {
    log_debug "run mkdir_billing_center_volume"

    if [ ! -d "$DATA_VOLUME_DIR" ]; then
        setup_directory "$JPZ_UID" "$JPZ_GID" 755 "$DATA_VOLUME_DIR"
    fi

    setup_directory "$JPZ_UID" "$JPZ_GID" 755 \
        "$DATA_VOLUME_DIR/billing-center" \
        "$DATA_VOLUME_DIR/billing-center/logs"

    log_info "åˆ›å»º billing_center volume ç›®å½•æˆåŠŸ"
}

remove_billing_center_volume() {
    log_debug "run remove_billing_center_volume"

    local confirm
    confirm=$(read_user_input "æ˜¯å¦åˆ é™¤ billing_center ç›¸å…³ volume æ•°æ® (é»˜è®¤n) [y|n]? " "n")
    if [ "$confirm" != "y" ]; then
        log_info "å–æ¶ˆåˆ é™¤ billing_center volume ç›®å½•"
        return
    fi

    if [ -d "$DATA_VOLUME_DIR/billing-center" ]; then
        sudo rm -rf "$DATA_VOLUME_DIR/billing-center"
        log_info "åˆ é™¤ $DATA_VOLUME_DIR/billing-center ç›®å½•æˆåŠŸ"
    fi
}

docker_build_billing_center() {
    log_debug "run docker_build_billing_center"

    # shellcheck disable=SC2329
    run() {
        cd "$ROOT_DIR" || exit

        git_clone_cd "billing-center"

        sudo docker build --no-cache -t "$REGISTRY_REMOTE_SERVER/billing-center:build" -f Dockerfile_dev .

        cd "$ROOT_DIR" || exit
        log_debug "è„šæœ¬æ‰€åœ¨ç›®å½• $(pwd)"
    }

    log_timer "æ„å»º billing-center é•œåƒ" run
}

docker_create_billing_center_temp_container() {
    log_debug "run docker_create_billing_center_temp_container"

    local run_func="$1"
    local version="$2"

    if sudo docker ps -a --format '{{.Names}}' | grep -Eq "^temp_container_blog_billing_center\$"; then
        sudo docker rm -f temp_container_blog_billing_center >/dev/null 2>&1 || true
    fi

    sudo docker create -u "$JPZ_UID:$JPZ_GID" --name temp_container_blog_billing_center "$(get_img_prefix)/billing-center:$version" >/dev/null 2>&1 || true

    $run_func

    sudo docker rm -f temp_container_blog_billing_center >/dev/null 2>&1 || true
}

DIR_ARTIFACTS_BILLING_CENTER="$DATA_VOLUME_DIR/billing-center/artifacts"
DIR_APP_BILLING_CENTER="$DATA_VOLUME_DIR/billing-center/artifacts/billing-center"

billing_center_artifacts_copy_to_local() {
    log_debug "run billing_center_artifacts_copy_to_local"

    local dir_artifacts=$DIR_ARTIFACTS_BILLING_CENTER
    local dir_app=$DIR_APP_BILLING_CENTER

    log_debug "dir_artifacts=====> $dir_artifacts"
    log_debug "dir_app=====> $dir_app"

    if [ ! -d "$dir_artifacts" ]; then
        sudo mkdir -p "$dir_artifacts"
    fi

    if [ -d "$dir_app" ]; then
        sudo rm -rf "$dir_app"
    fi
    sudo mkdir -p "$dir_app"

    # shellcheck disable=SC2329
    run_copy_artifacts() {
        sudo docker cp temp_container_blog_billing_center:/home/billing-center "$dir_artifacts"
    }

    docker_create_billing_center_temp_container run_copy_artifacts "build"

    log_info "billing-center äº§ç‰©å¤åˆ¶åˆ°æœ¬åœ°, äº§ç‰©è·¯å¾„: $dir_app"

    log_debug "billing-center ç‰ˆæœ¬: $(sudo cat "$dir_app/VERSION" 2>/dev/null)"
}

billing_center_artifacts_version() {
    local dir_app=$DIR_APP_BILLING_CENTER

    local version
    version=$(sudo cat "$dir_app/VERSION" 2>/dev/null)

    read -r version is_dev <<<"$(parsing_version "$version")"

    echo "$version" "$is_dev"
}

billing_center_artifacts_zip() {
    local version="$1"
    local dir_artifacts=$DIR_ARTIFACTS_BILLING_CENTER
    local dir_app=$DIR_APP_BILLING_CENTER

    local current_dir
    current_dir=$(pwd)

    cd "$dir_app" || exit

    zip_name="billing-center-$version.zip"

    log_debug "éœ€è¦æ‰“åŒ…çš„ç›®å½• $(pwd)"

    if [ -z "$(ls -A .)" ]; then
        log_error "billing-center äº§ç‰©ç›®å½•ä¸ºç©º, æ— æ³•æ‰“åŒ…"
        exit 1
    fi

    # shellcheck disable=SC2329
    run() {
        sudo zip -qr "../$zip_name" ./*
    }

    wait_file_write_complete run "../$zip_name"

    cd "$current_dir" || exit

    sudo rm -rf "$dir_app"

    echo "$dir_artifacts/$zip_name"
}

docker_push_billing_center() {
    log_debug "run docker_push_billing_center"

    billing_center_artifacts_copy_to_local

    local version_info
    version_info=$(billing_center_artifacts_version)
    read -r version is_dev <<<"$version_info"

    docker_tag_push_private_registry "billing-center" "$version"

    echo "ä¸å‘å¸ƒåˆ°ç”Ÿäº§ç¯å¢ƒ, ä»…æ¨é€åˆ°ç§æœ‰ä»“åº“"

}

docker_pull_billing_center() {
    log_debug "run docker_pull_billing_center"

    local version=${1-latest}

    # shellcheck disable=SC2329
    run() {
        timeout_retry_docker_pull "$REGISTRY_REMOTE_SERVER/billing-center" "$version"
    }
    docker_private_registry_login_logout run
}

wait_billing_center_start() {
    log_debug "run wait_billing_center_start"

    log_warn "ç­‰å¾… billing-center å¯åŠ¨, è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´... è¯·å‹¿ä¸­æ–­ï¼"

    local timeout=300
    local start_time
    start_time=$(date +%s)

    until sudo curl -sk "https://localhost/api/v1/helper/version" | grep -q "request_id"; do
        waiting 5

        local current_time
        current_time=$(date +%s)

        local elapsed_time=$((current_time - start_time))

        if [ "$elapsed_time" -ge "$timeout" ]; then
            log_error "billing-center å¯åŠ¨è¶…æ—¶, è¯·æ£€æŸ¥æ—¥å¿—æ’æŸ¥é—®é¢˜."
            exit 1
        fi
    done

    waiting 5

    log_info "billing-center å¯åŠ¨å®Œæˆ"
}

docker_billing_center_start() {
    log_debug "run docker_billing_center_install"
    sudo docker compose -f "$DOCKER_COMPOSE_FILE_BILLING_CENTER" -p "$DOCKER_COMPOSE_PROJECT_NAME_BILLING_CENTER" up -d

    wait_billing_center_start
}

docker_billing_center_stop() {
    log_debug "run docker_billing_center_stop"
    sudo docker compose -f "$DOCKER_COMPOSE_FILE_BILLING_CENTER" -p "$DOCKER_COMPOSE_PROJECT_NAME_BILLING_CENTER" down || true
}

docker_billing_center_restart() {
    log_debug "run docker_billing_center_restart"
    docker_billing_center_stop
    docker_billing_center_start
}

docker_billing_center_install() {
    log_debug "run docker_billing_center_install"

    local is_install
    is_install=$(read_user_input "æ˜¯å¦å…¨æ–°å®‰è£… billing_center (y/n)?" "n")

    if [ "$is_install" == "y" ]; then
        mkdir_billing_center_volume
        copy_billing_center_server_config
        copy_billing_center_nginx_config

        create_docker_compose_billing_center
        docker_billing_center_start

        log_info "billing_center å®¹å™¨å¯åŠ¨å®Œæˆ, è¯·ä½¿ç”¨ sudo docker ps -a æŸ¥çœ‹å®¹å™¨æ˜ç»†"

    else
        log_info "é€€å‡ºå…¨æ–°å®‰è£…"
    fi
}

docker_billing_center_delete() {
    log_debug "run docker_billing_center_delete"

    local is_delete
    is_delete=$(read_user_input "ç¡®è®¤åœæ­¢ billing_center æœåŠ¡å¹¶åˆ é™¤æ•°æ®å—(é»˜è®¤n) [y|n]? " "n")

    if [[ "$is_delete" == "y" ]]; then
        docker_billing_center_stop

        log_debug "is_delete=====> $is_delete"

        echo "$is_delete" | remove_billing_center_volume

        log_info "billing_center æœåŠ¡åŠæ•°æ®åˆ é™¤å®Œæˆ, è¯·ä½¿ç”¨ sudo docker ps -a æŸ¥çœ‹å®¹å™¨æ˜ç»†"
    fi
}

start_or_rollback_billing_center_by_version() {
    log_debug "run start_or_rollback_billing_center_by_version"

    read -r -p "è¯·è¾“å…¥ billing_center éœ€è¦å‡çº§æˆ–å›æ»šçš„ç‰ˆæœ¬å·: " version

    if [ -z "$version" ]; then
        log_error "ç‰ˆæœ¬å·ä¸èƒ½ä¸ºç©º, è¯·é‡æ–°è¿è¡Œè„šæœ¬å¹¶è¾“å…¥æ­£ç¡®çš„ç‰ˆæœ¬å·"
    fi

    docker_pull_billing_center "$version"

    docker_billing_center_stop

    create_docker_compose_billing_center "$version"

    docker_billing_center_restart

    log_info "æœåŠ¡ billing-center å·²æˆåŠŸå‡çº§æˆ–å›æ»šåˆ°ç‰ˆæœ¬ $version"
}

billing_center_logs() {
    log_debug "run billing_center_logs"

    printf "========================================\n"
    printf "    [ 1 ] æŸ¥çœ‹ billing-center å¸¸è§„æ—¥å¿—\n"
    printf "    [ 2 ] æŸ¥çœ‹ billing-center éªŒè¯ç æ—¥å¿—\n"
    printf "========================================\n"
    local user_input
    user_input=$(read_user_input "è¯·è¾“å…¥å¯¹åº”æ•°å­—æŸ¥çœ‹æ—¥å¿— [1-2]? " "1")

    local log_file filter_cmd

    case "$user_input" in
    1)
        log_file="$DATA_VOLUME_DIR/billing-center/logs/app.log"
        filter_cmd=()
        ;;
    2)
        log_file="$DATA_VOLUME_DIR/billing-center/logs/app.log"
        filter_cmd=("grep" "å‘é€éªŒè¯ç ")
        ;;
    *)
        log_warn "æ— æ•ˆè¾“å…¥ï¼š$user_input"
        return 1
        ;;
    esac

    if [ ! -f "$log_file" ]; then
        log_warn "$log_file, æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨æˆ–å½“å‰æ— æ—¥å¿—å¯æŸ¥çœ‹"
        return 1
    fi

    if [ ${#filter_cmd[@]} -eq 0 ]; then
        tail -f "$log_file"
    else
        tail -f "$log_file" | "${filter_cmd[@]}"
    fi
}

main() {
    disclaimer_msg
    check

    if [ $# -eq 0 ]; then
        show_logo

        print_options "$DISPLAY_COLS" "${OPTIONS_BILLING_CENTER[@]}"

        handle_user_input "${OPTIONS_BILLING_CENTER[@]}"
    else
        for arg in "$@"; do
            if func=$(is_valid_func OPTIONS_BILLING_CENTER_VALID[@] "$arg"); then
                exec_func "$func"
            else
                echo "æœªæ‰¾åˆ°ä¸è¾“å…¥åŒ¹é…çš„å‡½æ•°åç§°: $arg"
            fi
        done
    fi
}

main "$@"
